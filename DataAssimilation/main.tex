\documentclass[dvipdfmx, 9pt, a4paper]{jsarticle}
\usepackage[margin=15mm]{geometry}
\usepackage{fancyhdr}
\usepackage{multirow}
\usepackage{amsmath,  amssymb}
\usepackage{type1cm}
\usepackage{latexsym}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{ascmac}
\usepackage{listings,jvlisting}
\usepackage{tcolorbox}
\usepackage[utf8]{inputenc}
\usepackage{color}

\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{9}
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{9}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

\renewcommand{\baselinestretch}{0.78}
\newcommand{\bm}[1]{{\mbox{\boldmath $#1$}}}
\newtheorem{Proof}{証明}
\def\qed{\hfill $\Box$}

\newcommand\pythonstyle{\lstset{
language=Python,
basicstyle=\ttm,
morekeywords={self},
keywordstyle=\ttb\color{deepblue},
emph={MyClass,__init__},
emphstyle=\ttb\color{deepred},
stringstyle=\color{deepgreen},
frame=tb,
showstringspaces=false
}}

\lstnewenvironment{python}[1][]
{
\pythonstyle
\lstset{#1}
}
{}

\newcommand\pythonexternal[2][]{{
\pythonstyle
\lstinputlisting[#1]{#2}}}
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}


\begin{document}
\begin{center}
{\fontsize{18pt}{1pt}\selectfont データ同化}\\
\end{center}
\section*{はじめに}
私が思うに、CAE技術とは「対象の物理システムを計算機という別の物理システム上で表現する道具」である。計算機上での表現を正しいものにするために、高品質計算格子生成手法や高次差分技術など、いわゆる高精度CAE技術が研究されてきた。長年の技術発展の末、いまではCAE解析結果を信頼できるものと見なしている。更に、異なる分野にあったCAD技術と融合したことにより、既に製品開発でのCAE活用も当たり前になった。\par
一方でCAEの精度が向上するにつれ、CAE以外の問題が顕在化し始めた。例えばFEMでリビングルームの音響解析を行う場合にB.C.の情報が必要になるが、それらを正しく測定することは難しい(とくにソファーやカーテンの吸音特性)。B.C.以外にも、I.C.や物性値に誤りがあることは十分考えられる。CAE側で設定したこれらパラメータと実際の値に差異がある場合、正しくないCAE結果となることは当然であろう。これまで実現象に近づくよう発展してきたCAEだが、この問題はもはやCAE側の努力だけでは解決できない。\par
実現象とCAE結果のずれをなくす戦略のひとつとして、データ同化の利用が挙げられる。データ同化の解釈は驚くほど人それぞれだが、本資料では「CAEのためのベイズ機械学習」とする。データ同化は、B.C.など不確かなパラメータを学習対象とみなし、実空間から得た観測値(つまり教師データ)から学習する。これは線形回帰における、「$y=ax+b$」のうち$a$と$b$を学習対象とし、教師データ$\{ (x_i, y_i)|i=1,...,N \}$からパラメータを決定するアルゴリズムと同様である。\par
それゆえ、データ同化にとってCAEは$y=ax+b$のような数理モデル、いわばひな形にすぎない(表1)。データ同化の本質は「学習」にあり、その部分はベイズ機械学習が支えている。データ同化を勉強したいならば、たとえCAEエンジニアであってもAI技術に興味を持たなければならない。\par
本資料の目的はデータ同化の解説である。基礎から学べるように、確率論の概要から説明することにした。データ同化の和書で確率論から説明を開始している本はない。一方で確率論とベイズ機械学習を説明している書籍は多数存在する。それらの書籍よりも素晴らしい説明をする自信はないが、ベイズ機械学習の細かな内容を大胆に省くことで差異化を図った。ベイズ機械学習の適用先は広く、既存の本はそれら全てを説明しがちに思える。回り道と思える箇所は回避し、息切れすることなくデータ同化を習得できるよう心がけた。\bigskip \\
(文責：TL25 中西　佑児)

\begin{table}[b]
\begin{center}
\caption{線形回帰とデータ同化の類似性}
\begin{tabular}{c|ccc}
\hline
 & モデル & 教師データ & 学習対象 \\ \hline
線形回帰 & $y=ax+b$ & $\{ x_i, y_i \}$ & $a, b$ \\
データ同化 & CAE & 観測値 & B.C., I.C., 物性値など \\ \hline
\end{tabular}
\end{center}
\end{table}

\section{確率論}
実現象とCAEにずれがあり、その原因がCAE側の誤ったパラメータ設定にあるならば、この問題を「実現象に近づくことを是としたパラメータの最尤値探査」と考えないのはなぜか。最尤値探査は勾配降下法などで達成できるので、本章の確率論は不要に思える。\par
この指摘は案外的を得ているが、「実現象がいつも正しい値を提供する」ことを前提としている点で惜しい。表1中の観測値はセンサなどから得られるため、ノイズの存在は認めるべきである。不確かさのある結果を対象にした最尤値探査である以上、やはり確率論は必要になってくる。確率論と最尤値探査を組み合わせてようやく機械学習らしくなる。何より最尤値以外も重要なことだってあるだろう。観測結果をある値に言い切れない以上、推定対象のパラメータも言い切れないはずである(この考えはベイズ統計特有のもので、頻度主義の統計学では見られない)。「どの程度言い切れないか」の定量的表現は工学的にもビジネス的にも価値がある。

\subsection{確率変数と確率分布}
\subsubsection{確率変数}
データ同化ではセンサノイズのような変動する数値(つまり変数)を扱う。変数は離散的であっても連続的であってもよいが、データ同化では専ら連続変数を扱う。しかしながら、離散変数の観点も非常に重要であるため、本資料では両方を取り扱うことにする。\par
例えばサイコロの出る目を変数$X$で表したとき、$X$の取り得る値は$\{ 1,2,3,4,5,6 \}$のいずれかである。一般的な解析学の場合、変数の定義域を知るだけで十分に価値があった。しかしながら統計学の場合はそうもいかない。取り得る各値が起こる確率も興味の対象になってくる。このように、確率情報を有する変数のことを確率変数と言う。
\begin{tcolorbox}[title=確率変数]
　変数が取り得る各値(実現値)に対して確率が与えられているとき、その変数を特別に確率変数と言う。確率変数の実現値は離散的であっても連続的であってもよい。前者を離散確率変数、後者を連続確率変数と言う。
\end{tcolorbox}
統計学の慣習では、確率変数を大文字$(X, Y, Z, ...)$、実現値を小文字$(x, y, z, ...)$で表記する。ただしデータ同化では統計学よりも工学の慣習に従うことの方が多い。例えば質量値が不確かな問題を扱う場合、その確率変数を$M$と無理に表すのではなく$m$の方を採用する。\bigskip

\begin{itembox}[l]{確率変数の例}
{\bf サイコロ} \par
　確率変数に慣れるためにサイコロを例にして考えよう。前述の通り、サイコロの出る目に関する確率変数$X$は$\{ 1,2,3,4,5,6 \}$を取り得る。この実現値の全体集合のことを標本空間と言い、$\Omega$で書き表すことが多い。また、$X=x$となるときの確率を${\rm Pr}(X=x)$と書く。理想的なサイコロであれば任意の$x$に対して${\rm Pr}(X=x)=1/6$となる。\par
　$X$が$\Omega$の部分集合$W$のいずれかとなる確率を、${\rm Pr}(X \in W)$と書いてもよい。たとえば$X$が奇数となる確率は${\rm Pr}(X \in \{ 1,3,5 \})=1/2$である。当然ながら、${\rm Pr}(X \in \Omega)=1$である。\bigskip \\
{\bf ステーキのグラム数}\par
　レストランで提供されるステーキのグラム数も表記から多少はずれているだろう。グラム数に関する確率変数$G$は連続確率変数に分類される。連続という違いはあれど内容はサイコロの例と変わらない。ステーキがいつも1000 gのブロック肉からカットして提供している場合、$G$の標本空間は$\Omega = \{ g | g \in [0, 1000] \}$になる。$G=g$となるときの確率は${\rm Pr}(G=g)$と表記され、$G \in (a, b)$となる確率は${\rm Pr}(G \in (a, b))$で表される。当然ながら${\rm Pr}(G \in \Omega)=1$でなければならない。\bigskip \\
{\bf くじ引き}\par
　2つの箱$A$と$B$があり、それぞれに白玉と黒玉が入っているとする(図1)。ここで玉を1つ取り出すゲームを考えよう。プレイヤーは箱$A$と$B$をランダムに選択し、各箱の中の玉もランダムに取り出すとする。\par
　箱$A$から白玉を取り出す確率を表現するには、箱に関する確率変数$X \in \{ A, B \}$と玉の色に関する確率変数$Y \in \{ W, B \}$が必要になる(同じ色の玉は区別できないと仮定した)。$X$と$Y$を用いることで、この確率は${\rm Pr}(X=A, Y=W)$と表現できるようになる。\par
　このように複数の確率変数を用いることは問題にならない。${\rm Pr}(X=A, Y=W)$のことを「$(X=AかつY=W$の同時確率」と言う。確率変数の数が多すぎて列挙するのが難しい場合、$\bm Z=(X, Y)^{\rm T}$のように確率変数をベクトルで纏め、${\rm Pr}(\bm Z = \bm z)$のように表記してもよい。このような確率変数を多次元確率変数と言う。$X$と$Y$の標本空間から、$\bm Z$の標本空間は$\{ (A, W), (B, W), (A, B), (B, B) \}$であると分かる。 \bigskip \\
{\bf アーチェリー}\par
　座標(0, 0)に的の中心があるアーチェリーの問題を考える。選手はよく訓練されており、横方向にも縦方向にも1 cm以上軸から外さない。この場合、横軸方向のずれに関する確率変数$X$と縦軸方向の確率変数$Y$を考えることができる。また、$X$と$Y$の標本空間はどちらも$[-1,1]$となる。\bigskip \\
{\bf ランダムウォーク}\par
　時系列のある問題でも確率変数はよく現れる。例えばランダムウォークの問題を考えよう。各時刻の座標を$X_t$(連続値)とし、時刻$T$まで移動を行ったとする。このとき、時系列$\{ x_1, x_2, ..., x_T \}$が得られる確率は${\rm Pr}(X_1=x_1, X_2=x_2,..., X_T=x_T)$のように表記できる。
\end{itembox}

\begin{figure}[tb]
\begin{center}
\includegraphics[width=7cm]{"fig1.png"}
\caption{くじ引きの例}
\end{center}
\end{figure}

\subsubsection{確率分布}
確率分布とは確率変数と確率の関係を関数で表現したものである。離散と連続のどちらに対しても使うことのできる言葉だが、その厳密な意味は両者で大きく異なる。形式張った議論では離散確率変数に対する確率分布を「確率質量関数」、連続確率変数に対する確率分布を「確率密度関数」と区別する。 \bigskip \\
{\bf 離散確率変数に対する確率分布}
\begin{tcolorbox}[title=確率質量関数]
　離散確率変数$X$を考える。$X=x$となる確率${\rm Pr}(X=x)$が$p(X=x)$で表されるとき、関数$p$を$X$の確率質量関数、もしくは単に確率分布と呼ぶ。
\end{tcolorbox}
なお、$p(X=x)$という書き方は厳密であるが、$p(X)$と省略して書く人も多い。このときは確率変数$X$が実現値$X$であるときの確率と解釈する(確率変数と実現値に対して同じ表記を使うことに違和感を感じるかもしれないが、次第になれる)。\par
確率の公理(つまり確率は非負で総和は1)より、確率質量関数$p$は任意の実現値に対して
\begin{equation}
0 \leq p(X) \leq 1
\end{equation}
\begin{equation}
\sum_\Omega p(X) = 1
\end{equation}
であることが言える。\bigskip
\begin{itembox}[l]{確率質量関数の例}
{\bf サイコロ} \par
　理想的なサイコロであれば、確率質量関数は、任意の$x \in \{ 1,2,3,4,5,6 \}$に対して$p(X=x)=1/6$が成立する。\bigskip \par
{\bf くじ引き(1.1.1節)}\par
　1.1.1節のくじ引きに関して、箱の選択確率をそれぞれ1/2とし、玉も平等に選択されるとする。このとき、図1から明らかに
\begin{equation}
p(X=A, Y=W)=\frac{2}{7} \notag
\end{equation}
\begin{equation}
p(X=A, Y=B)=\frac{3}{14} \notag
\end{equation}
\begin{equation}
p(X=B, Y=W)=\frac{5}{14} \notag
\end{equation}
\begin{equation}
p(X=B, Y=B)=\frac{1}{7} \notag
\end{equation}

だと分かる。
\end{itembox} \bigskip \\
{\bf 連続確率変数に対する確率分布}
\begin{tcolorbox}[title=確率密度関数]
　連続確率変数$X$を考える。$X$の値が$X \in (x, x+\delta x)$を満たすときの確率が
\begin{equation}
\int_x^{x+\delta x}p(X)dX
\end{equation}
で表されるとき、関数$p$を$X$の確率密度関数と呼ぶ。
\end{tcolorbox}
このように連続確率変数の場合、確率値の導出に積分計算が必要になる。なお、$X$の値がちょうど$x$となる確率は
\begin{equation}
{\rm Pr}(X=x)={\rm lim}_{\delta x \to 0} p(x)\delta x \notag
\end{equation}
で定義される。確率の公理より確率密度関数は
\begin{equation}
0 \leq p(X)
\end{equation}
\begin{equation}
\int_\Omega p(X)\delta X=1
\end{equation}
を満たさなければならない($p(X) \leq 1$を満たす必要がないことに注意)。\bigskip
\begin{itembox}[l]{確率密度関数の例}
　1.1.1節のステーキグラム数を例にして考える。200 gのステーキの注文をしたときの実際のグラム数に関して、確率密度関数$p(G)$は正規分布(ガウス分布)
\begin{equation}
p(G)=\frac{1}{\sqrt{18\pi}}{\rm exp}\left(-\frac{(G-200)^2}{18} \right) \notag
\end{equation}
に従うとする。1.1.1節では標本空間を[0,1000]に限定したにも関わらず、正規分布は任意の実数に対して定義されている。これは、$\int_\Omega p(G) dG=\int_0^{1000} p(G) dG=1$を満たす確率分布を探すのが面倒だったためである。便宜的に$G$の標本空間を実数全体にし、正規分布を採用した。標本空間[0,1000]外の確率密度関数値が十分にゼロに近いのであれば、このような操作はあまり問題にならない。\par
　$G$が上記の正規分布に従う場合、ステーキのグラム数が197から203になる確率は
\begin{equation}
p(G)=\frac{1}{\sqrt{18\pi}} \int_{197}^{203} {\rm exp}\left(-\frac{(G-200)^2}{18} \right) dG \notag
\end{equation}
となる。この積分計算をする代わりに$Z=(G-200)/3$で変数変換し、
\begin{equation}
p(Z)=\frac{1}{\sqrt{18\pi}} \int_{-1}^{1}{\rm exp}\left(-\frac{Z^2}{2} \right) dZ
=\frac{1}{\sqrt{18\pi}} \int_{-\infty}^{1}{\rm exp}\left(-\frac{Z^2}{2} \right) dZ
-\frac{1}{\sqrt{18\pi}} \int_{-\infty}^{-1}{\rm exp}\left(-\frac{Z^2}{2} \right) dZ \notag
\end{equation}
の積分計算を考える(上式の最右辺は関数の対称性より導いた)。実は$(2\pi)^{1/2}\int_{-\infty}^{a}{\rm exp}(-0.5Z^2) dZ$の積分($a$は任意の実数)は統計学において非常に有名である。統計学の書籍の巻末にテーブルデータとして必ずある程で、それを引用して上式を求めることができる。私も計算を続けるのは面倒なので、ここで切り上げさせて頂く(ちなみに答えは0.683)。
\end{itembox}

\subsection{確率論の基礎}
\subsubsection{加法定理}
改めて1.1.2節のくじ引きの例を考える。この問題は2つの確率変数($X$と$Y$)を扱っているが、例えば、「どちらの箱が選ばれたかは問わず、とにかく白玉が選択された確率」、つまり$p(Y=W)$を知りたいこともある。この問は高校数学でもよく見かけた。当然ながら
\begin{equation}
p(Y=W)=p(X=A, Y=W)+p(X=B, Y=W) \notag
\end{equation}
より求まる。この解き方は確率の加法定理を利用している。
\begin{tcolorbox}[title=加法定理]
　離散確率変数$X$と$Y$を考える。確率質量関数$p(X, Y)$に対して、$p(Y)$は
\begin{equation}
p(Y)=\sum_x p(X=x, Y)
\end{equation}
で求めることができる。\par
　加法定理は連続確率変数に対しても成立する。確率密度関数$p(X, Y)$に対し、$p(Y)$は
\begin{equation}
p(Y)=\int p(X, Y)dX
\end{equation}
で求められる。\par
連続であれ離散であれ、$p(X, Y)$から求められた$p(Y)$のことを周辺確率と言う。
\end{tcolorbox}
\begin{itembox}[l]{周辺確率の例}
{\bf くじ引き(1.1.2節)}\par
　箱の選択を問わず、ただ黒玉が選択される確率を計算したい場合、加法定理より
\begin{equation}
p(Y=B)=p(X=A, Y=B)+p(X=B, Y=B)=\frac{3}{14}+\frac{1}{7}=\frac{5}{14} \notag
\end{equation}
と求まる。
\end{itembox}

\subsubsection{乗法定理}
再度1.1.2節のくじ引きの例を考える。黒玉を引く可能性は先ほどの例より5/14であった。しかしながら、前もって箱$A$を選択すると分かっている場合、黒玉を引く確率は図1より3/7になる。\par
このように、事前情報が加わると不確かさも変わる。新しく求めた確率3/7は${\rm Pr}(X=A, Y=B)$と異なる。後者を高等数学流に言うなら、「$X=A$かつ$Y=B$の確率」に相当する。他方事前情報の加わった確率は「$X=A$のとき$Y=B$である確率」と表現できる。後者の確率を条件付確率と言い、${\rm Pr}(Y=B|X=A)$と書き表す($|$のことをギブンと呼ぶ)。これまで同様、条件付確率を${\rm Pr}(Y|X)$と略記してもよい。\par
${\rm Pr}(Y=B|X=A)$は$X=A$が起こることを前提にしている。したがって、以下の乗法定理が成り立つ。
\begin{tcolorbox}[title=乗法定理]
確率変数$X$と$Y$を考える。このとき、
\begin{equation}
{\rm Pr}(X, Y)={\rm Pr}(X|Y){\rm Pr}(Y)
\end{equation}
が成立する。
\end{tcolorbox}
もちろん、どちらを前提に持ってきてもよいので、式(8)同様${\rm Pr}(X,Y)={\rm Pr}(Y|X){\rm Pr}(X)$も成立する。これと式(8)より、ベイズの定理を導くことができる。
\begin{tcolorbox}[title=ベイズの定理]
乗法定理より
\begin{equation}
{\rm Pr}(X|Y)=\frac{{\rm Pr}(Y|X){\rm Pr}(X)}{{\rm Pr}(Y)}
\end{equation}
が成立する。
\end{tcolorbox}
左辺にとって$Y$の値は前提となっている。つまり$Y$はすでに決まっていると考えることができる。すると右辺の${\rm Pr}(Y)$はもはや定数と考えてもよい。いわば確率分布${\rm Pr}(Y|X){\rm Pr}(X)$が確率の公理(総和が1)を満たすための規格化係数にすぎないので、ベイズの定理は
\begin{equation}
{\rm Pr}(X|Y) \propto {\rm Pr}(Y|X){\rm Pr}(X)
\end{equation}
と書かれることもある。\par
ベイズの定理に関して、両辺で前提となっているものが入れ替わっていることに注目してほしい。人によっては${\rm Pr}(X|Y)$のうち$Y$を原因、$X$を結果と呼ぶ。したがってベイズの定理は因果を反転させる式として便利である。\bigskip
\begin{itembox}[l]{ベイズの定理の例}
　おなじみのくじ引きの例を考える(1.1.2節)。1.1.2節の例より、箱$A$が選択される確率は1/2であった。ここでは「白玉が出たとき、それが箱$A$からのものである確率」${\rm Pr}(X=A|Y=W)$を考える。${\rm Pr}(Y=W|X=A)$は図1より明らかだが、${\rm Pr}(X=A|Y=W)$の計算は意外と難しい。そこでベイズの定理が登場する。\par
　まず、$p(X=A)$は1/2、$p(Y=W|X=A)$は4/7なので、式(9)より
\begin{equation}
p(X=A|Y=W)=\frac{p(Y=W|X=A)p(X=A)}{C}=\frac{2}{7C} \notag
\end{equation}
となる。ここで$C$は$p(Y=W)$だが、規格化係数であることを強調するため$C$という書き方にした。$C$の計算のために直接$p(Y=W)$を求める人もいるが、その代わりに
\begin{equation}
p(X=B|Y=W)=\frac{p(Y=W|X=B)p(X=B)}{C}=\frac{5}{14C} \notag
\end{equation}
を求め、確率の公理$p(X=B|Y=W)+p(X=A|Y=W)=1$から規格化定数$C$を求めることもできる。$p(Y)$よりも$p(X)$や$p(X|Y)$の計算の方が楽な場合は、この方法を用いるべきだろう。最終的に、本問題の解は4/9だと求まる。
\end{itembox}\bigskip \par
条件確率に関して$p(X|Y)=p(X)$が成立するとき、$X$と$Y$は独立であるという。この結果は$Y$の結果が$X$に影響を及ぼさないことを示している。たとえば2個のサイコロを投げる問題を考えよう。それぞれのサイコロを区別して考えるとき、確率変数は2つ必要になる($X$と$Y$とする)。当然ながら$X$の実現値は$Y$の結果に影響を及ぼさない。確率変数に独立の関係があると同時確率が
\begin{equation}
p(X,Y)=p(X|Y)p(Y)=p(X)p(Y) \notag
\end{equation}
のように、各変数を単独に考えたときの確率の積になり、計算がシンプルになってくれる。\par
これと似た概念にマルコフ性というものがある。時系列に関する確率変数$(X_1, X_2, ..., X_T)$において、
\begin{equation}
p(X_t|X_{t-1}, X_{t-2}, ..., X_1)=p(X_t|X_{t-1})
\end{equation}
が成立するとき、確率変数はマルコフ性を有すると言う。これは、$X_t$に関する条件付確率が前時刻の実現値にのみ依存することを意味している。

\subsection{確率分布の代表値}
代表値とは確率分布の特性を表す指標である。本資料では基礎中の基礎とも言える3つの代表値を紹介する。

\subsubsection{期待値}
「確率変数が取るであろうと期待される値」のことを期待値という。一般的に確率変数$X$の期待値を$E[X]$と表記し、確率分布による重み付き和で定義する。つまり、離散確率変数の場合は
\begin{equation}
E[X]=\sum_{X \in \Omega} Xp(X)
\end{equation}
であり、他方連続確率変数の場合は
\begin{equation}
E[X]=\int_\Omega Xp(X)dX
\end{equation}
となる。また、$E[\cdot]$という表記は$X$を任意の関数で変換させた確率変数$f(X)$に対しても使える。この$E[f(X)]$は離散と連続のそれぞれで
\begin{equation}
E[X]=\sum_{X \in \Omega} f(X)p(X)
\end{equation}
\begin{equation}
E[X]=\int_\Omega f(X)p(X)dX
\end{equation}
となる。$X$を$aX+b$に変換させたとき($a, b$はスカラー)、$E[aX+b]$は上式より
\begin{equation}
E[aX+b]=aE[X]+b
\end{equation}
だとわかる。

\subsubsection{分散}
確率分布の広がりを表す代表値に分散がある。一般的に確率変数$X$の分散を$V[X]$と書く。$V[X]$は期待値の表記$E[\cdot]$を用いて、
\begin{equation}
V[X]=E\left[ (X-E[X])^2 \right]
\end{equation}
と定義されている。式(17)より、分散値は非負だと分かる。また、確率変数が一つの値のみ取り得る場合に限って、分散はゼロになる。\par
確率変数を$aX+b$に線形変換したとき、分散は
\begin{equation}
V[aX+b]=a^2V[X]
\end{equation}
と求まる。

\subsubsection{共分散}
多次元確率変数$\bm X=(X_1, X_2, ..., X_n)^{\rm T}$における、任意の要素$X_i$と$X_j$に対して、共分散
\begin{equation}
{\rm Cov}[X_i, X_j]=E\left[ (X_i-E[X_i])(X_j-E[X_j]) \right]
\end{equation}
が定義されている。共分散は確率変数間の相関を表している。共分散が正(負)のとき、確率変数間には正(負)の相関がある。また、共分散がゼロのとき確率変数同士は無相関である。同様に独立な確率変数同士の共分散はゼロになる。なお、$i=j$のとき、共分散は分散と同じになる。\par
$i$行$j$列に${\rm Cov}[X_i, X_j]$が入る$n$次正方行列のことを分散共分散行列という。式(19)より、分散共分散行列は対象行列であることが分かる。また、任意の確率変数同士が独立である場合、分散共分散行列は対角行列になる。

\subsection{確率分布の表現方法}
ここまで「確率分布は関数である」と紹介してきたが、そもそもの関数についてあまり深く考えてこなかったと思う。数学において関数は以下のように定義されている。つまり、集合$X$の元$x$のそれぞれに、ある規則にしたがって集合$Y$の元$y$を一つずつ対応させるとき、この対応規則を関数と言い、$f: x \to y=f(x)$のように書く。\par
単なる対応規則であると考えることができれば、本節の理解は捗るだろう。本節では、離散確率変数と連続確率変数に分けて、パラメトリック確率分布とノンパラメトリック確率分布の概念を紹介する。

\subsubsection{離散確率分布の場合}
\begin{table}[t]
\begin{center}
\caption{ノンパラメトリック確率分布(サイコロの場合)}
\begin{tabular}{c|cccccc}
$x$ & 1 & 2 & 3 & 4 & 5 & 6\\ \hline
$p$ & 1/6 & 1/6 & 1/6 & 1/6 & 1/6 & 1/6 \\
\end{tabular}
\end{center}
\end{table}

離散確率分布の表し方は大きく分けて2種類ある。いま、$n$種(有限)の実現値$\{ x_i|i=1,...,n \}$を取り得る確率変数$X$を考えよう。最も単純な確率分布の表現方法は、各$x_i$に対応する確率値$p_i$を用意し、テーブルデータとして保存する方法であろう。例えばサイコロの場合、出る目とその確率値は表2のように表現することができる。高等教育で学んだ確率は確か離散変数で、私たちも表2のようなテーブルデータを思い浮かべながら問題を解いていたはずである。テーブルデータによる表現は非常にシンプルで、計算機にとって扱いやすい。しかしながら確率変数の取り得る値$n$が大きくなると、当然それに要するメモリも多くなる。実現値と対応する確率値を合わせて保存しなければならないため、個数$n$に対してテーブルデータの数値の個数は$2n$になる。場合によってはメモリの制約上、テーブルデータによる表現方法を避けなければならない。\par
もう一つの確率分布の表現方法はパラメトリック確率分布と呼ばれている。これは、表2のようなデータを関数でフィッティングする方法と思えばよい。たとえば単変数かつ離散確率変数において有名なパラメトリック確率分布にポアソン分布
\begin{equation}
p(X)=\frac{e^{-\lambda}\lambda^X}{X!} \notag
\end{equation}
がある(ポアソン分布の$X$の取り得る値は非負の整数のみ)。ポアソン分布はパラメータ$\lambda$を持ち、対象の確率変数に対してフィッティングしなければならない(もちろん理論的観点からパラメータの適切な値が求まり、フィッティングを必要としない場合もある)。フィッティングである以上誤差があるかもしれないが、上手く近似できた場合、確率分布情報の保存はパラメータ分だけのメモリで済む。ポアソン分布の場合$\lambda$の数値のみ保存すればよいことになるので、$n$の数によっては大幅なメモリ節約になる。\par
パラメトリック確率分布に対して、テーブルデータによる表現方法をノンパラメトリック確率分布と言う。個人的にはテーブルデータによる表現が好きだが、パラメトリック確率分布と合わせるために
\begin{equation}
p(X)=\sum p_i \delta(X-x_i)
\end{equation}
のように書くことも多い(確率の公理より$\sum p_i=1$)。このような表現ゆえに、ノンパラメトリック確率分布は初学者にとって難しいとされている。しかしながら手計算とはいえ高等教育で扱っていたことを思い出すと、その認識は大げさな気もする。また、数値計算との相性も悪くないので、あまりノンパラメトリック確率分布を毛嫌いすべきでないようにも思える。\par
さて、繰り返しになるがパラメトリック確率分布ではパラメータの調整、つまり学習が必要になる。ポアソン分布の場合の学習対象は$\lambda$のみなので、その表現力の乏しさが想像できる(一方のノンパラメトリック確率分布は表現力の点で優れている)。ポアソン分布以外にも数多くのパラメトリック確率分布が提案されているが(本資料では紹介しない)、いずれもパラメータ数は少ない。近年の研究では、これら分布の代わりに深層学習を用いることの方が多い(とはいえデータサイエンティストは今でも伝統的な確率分布を上手く利用している)。

\subsubsection{連続確率分布の場合}
連続確率変数でもパラメトリック確率分布とノンパラメトリック確率分布がある。パラメトリック確率分布の代表例に正規分布
\begin{equation}
p(X)=\frac{1}{\sqrt{2\pi \sigma^2}}{\rm exp}\left( -\frac{(X-\mu)^2}{2\sigma^2} \right) \notag
\end{equation}
がある(正規分布のパラメータは$\mu$と$\sigma^2$のみ)。パラメトリック確率分布ゆえにフィッティングさえ上手くいけば、確率分布の情報はパラメータ値に集約される(つまりメモリへの負担が少ない)。\par
連続確率変数におけるノンパラメトリック確率分布の表現方法は主に2通りある。\bigskip \\
{\bf 確率変数空間の離散化}\par
本来なら、連続確率変数の取り得る実現値は無数に存在するため、離散確率変数におけるテーブルデータ(表2)のような表現方法はできない。そこで、連続確率変数の場合は解析者の手で実現値を離散化する。つまり、無数に取り得た実現値$\{ x|x \in \Omega \}$を有限個の実現値$\{ x_i|i=1,...,n \}$で近似してしまう。さらに、各実現値$x_i$に対して確率密度関数値$p(x_i)=p_i$を定義することで、連続確率変数におけるノンパラメトリック確率分布の表現を得る。これはCAEにおける離散化の考えと非常に似ている(CAEも時空間を離散化し、連続体力学の物理場を有限次元の状態ベクトルで表現してしまう)。離散確率変数におけるノンパラメトリック確率分布は決して近似的表現方法でない一方、連続確率変数におけるそれは近似的である。しかしながら、CAEとの類似性から分かるように、離散数$n$を増やすほど近似による誤差は小さくなっていく。\par

\begin{figure}[t]
\begin{center}
\includegraphics[width=14cm]{"fig2.png"}
\caption{(a)連続確率分布のパラメトリック表現(b)離散化によるノンパラメトリック表現}
\end{center}
\end{figure}

図2に同じ確率分布に対するパラメトリック表現とノンパラメトリック表現の対比を示す。図2(b)は表2のようにテーブルデータで表現することもできるし、式(20)同様、
\begin{equation}
p(X) \simeq \sum p_i \delta(X-x_i)
\end{equation}
のように書き表すこともできる(確率の公理より$\sum p_i=1$)。ノンパラメトリック確率分布を上式で定義した場合、確率分布の代表値計算は離散確率変数のときのようになる。例えば期待値は式(13)から、
\begin{equation}
\int_\Omega Xp(X)dX=\int_\Omega X\sum p_i\delta(X-x_i)dX=\sum x_i p_i \notag
\end{equation}
となり、式(12)と同様になる。\bigskip \\
{\bf アンサンブルによる表現}\par
所望の確率分布$p(X)$に従ってサンプリングし、$\{ x_i|i=1,...,N \}$を得たとする。このサンプルデータに対して、重複するものを一つに纏め、新たにデータセット$\{ x'_i|i=1,...,n \}(n\leq N)$を作る。また、$\{ x_i|i=1,...,N \}$の中に$x'_i$は$n_i$個あったとしよう(従って$\sum_in_i=N$)。すると、$x'_i$がサンプリングされる確率は$n_i/N$だと分かるので(頻度主義の確率。頻度主義は2章で説明する)、式(21)より、$p(X)$を
\begin{equation}
p(X) \simeq \sum_i \frac{n_i}{N} \delta(X-x'_i) \notag
\end{equation}
と近似できる。ただし、上式は重複を許す形で、
\begin{equation}
p(X) \simeq \sum_i\frac{n_i}{N}\delta(X-x'_i) = \frac{1}{N} \sum_i \delta(X-x_i)
\end{equation}
と書き直すこともできる(一般的には式(22)の表記が使われる)。\par
このように、サンプリング結果の重複度合いで確率密度関数値の大きさを表現する。アンサンブルによる表現の利点はサンプリングの容易さにある。式(22)の最右辺で表された確率分布に対して、その分布に従うようサンプリングするには、データセット$\{ x_i|i=1,...,N \}$からそれぞれ$1/N$の確率で選択すればよいことに気付く。頻度主義的に、$p(X)$の精度はサンプル数とともに増加する。

\subsection{正規分布}
データ同化で扱う確率変数は専ら連続で、パラメトリック確率分布に正規分布を採用することが多い。本節では正規分布とその特徴を紹介する。
\subsubsection{単変数の正規分布}
単変数の正規分布は
\begin{equation}
p(X)=\frac{1}{\sqrt{2\pi \sigma^2}}{\rm exp}\left( -\frac{(X-\mu)^2}{2\sigma^2} \right)
\end{equation}
で表される。正規分布のパラメータは$\mu$と$\sigma^2$で、それぞれ確率分布の期待値および分散と一致する。正規分布は$\mathcal{N}(X|\mu, \sigma^2)$、もしくは単純に$\mathcal{N}(\mu, \sigma^2)$と表記されることが多い。統計学において、期待値ゼロかつ分散1の正規分布$\mathcal{N}(0,1)$は非常に重要であり、特別に標準正規分布と呼ばれている。
\begin{tcolorbox}[title=正規分布の線形変換]
　確率変数$X$は正規分布$\mathcal{N}(\mu, \sigma^2)$に従うとする。スカラー$a, b$で線形変換された確率変数$aX+b$も正規分布$\mathcal{N}(a\mu+b, a^2\sigma^2)$に従う。
\end{tcolorbox}
上記より、任意の正規分布$\mathcal{N}(\mu, \sigma^2)$は標準正規分布の線形変換
\begin{equation}
X=\sigma Z+\mu \notag
\end{equation}
より得られる($Z$は標準正規分布に従う確率変数)。\par
正規分布に従う確率変数$X$に非線形変換をしたとき、変換後の確率変数は正規分布に従わないと認識している。ただし、「如何なる非線形変換も正規分布を維持できない」と言い切れるのかどうかを、私は知らない。
\begin{tcolorbox}[title=正規分布の和]
　$\mathcal{N}(\mu_1, \sigma_1^2)$に従う確率変数$X$と$\mathcal{N}(\mu_2, \sigma_2^2)$に従う確率変数$Y$を考える。このとき、$X+Y$も正規分布$\mathcal{N}(\mu_1+\mu_2, \sigma_1^2+\sigma_2^2)$に従う。
\end{tcolorbox}
\begin{tcolorbox}[title=正規分布の積]
　$\mathcal{N}(\mu_1, \sigma_1^2)$に従う確率変数$X$と$\mathcal{N}(\mu_2, \sigma_2^2)$に従う確率変数$Y$を考える。このとき、$XY$も正規分布$\mathcal{N}(\mu, \sigma^2)$に従う。ただし、
\begin{equation}
\mu=\frac{\sigma^2_2\mu_1+\sigma^2_1\mu_2}{\sigma^2_1+\sigma^2_2} \notag
\end{equation}
\begin{equation}
\sigma^2=\frac{\sigma^2_1\sigma^2_2}{\sigma^2_1+\sigma^2_2} \notag
\end{equation}
である。
\end{tcolorbox}

\subsubsection{多変数の正規分布}
多変数の正規分布は
\begin{equation}
\mathcal{N}(\bm X|\bm \mu, \Sigma)=\frac{1}{(2\pi)^{D/2}}\frac{1}{|\Sigma|^{1/2}}
{\rm exp}\left( -\frac{1}{2}(\bm X - \bm \mu)^{\rm T}\Sigma^{-1}(\bm X - \bm \mu) \right)
\end{equation}
で表される。正規分布のパラメータは$\bm \mu$と$\Sigma$で、それぞれ確率分布の期待値と分散共分散行列と一致する。また、$D$は確率変数の次元で、演算子$|\cdot|$は行列式である。確率分布$\mathcal{N}(\bm 0, I)$は特別に標準正規分布と呼ばれている。
\begin{tcolorbox}[title=正規分布の線形変換]
　確率変数$\bm X$は正規分布$\mathcal{N}(\bm \mu, \Sigma)$に従うとする。行列$A$とベクトル$\bm b$を用いて、$A\bm X+\bm b$なる線形変換を施したとき、
\begin{equation}
p(A\bm X+\bm b)=\mathcal{N}(A\bm \mu+\bm b, A\Sigma A^{\rm T}) \notag
\end{equation}
が成立する。
\end{tcolorbox}
\begin{tcolorbox}[title=正規分布の和]
　多次元正規分布$\mathcal{N}(\bm \mu_1, \Sigma_1)$に従う確率変数$\bm X$と$\mathcal{N}(\bm \mu_2, \Sigma_2)$に従う確率変数$\bm Y$を考える。このとき、$X+Y$も正規分布$\mathcal{N}(\bm \mu_1+\bm \mu_2, \Sigma_1+\Sigma_2)$に従う。
\end{tcolorbox}
\begin{tcolorbox}[title=正規分布の積]
　多次元正規分布$\mathcal{N}(\bm \mu_1, \Sigma_1)$に従う確率変数$\bm X$と$\mathcal{N}(\bm \mu_2, \Sigma_2)$に従う確率変数$\bm Y$を考える。このとき、$XY$も正規分布$\mathcal{N}(\bm \mu, \Sigma)$に従う。ただし、
\begin{equation}
\bm \mu=\Sigma_2(\Sigma_1+\Sigma_2)^{-1} \bm \mu_1+
\Sigma_1(\Sigma_1+\Sigma_2)^{-1} \bm \mu_2 \notag 
\end{equation}
\begin{equation}
\Sigma=\Sigma_1(\Sigma_1+\Sigma_2)^{-1}\Sigma_2 \notag
\end{equation}
である。
\end{tcolorbox}

\section{ベイズ機械学習}
本資料の冒頭で「データ同化の本質はベイズ機械学習にある」と述べた。したがって、本章の内容は非常に重要になってくる。しかしながらベイズ統計の隅々まで本資料で紹介することは不可能なので、線形回帰における機械学習の紹介に留める。ただし、それだけでもデータ同化の学習に支障はない。なぜならデータ同化において利用する数理モデルは基本的にCAEであり、その他の数理モデル(深層学習など)を深く学ぶ必要はないためである。\par
ここで、本資料をお読みいただいた皆様の立ち位置を確認しよう。皆様は確率論を学んだに過ぎず、まだ統計学に触れていない。それどころか、実は確率の決め方すら学んでいないことにも気付く。例えばサイコロで1が出る確率=1/6に関して、この1/6が何を根拠に決められたのか説明できない。\par
結論から言うと、確率には頻度主義と呼ばれるものと主観確率と呼ばれるものがある。「確率」という1つの言葉に2つの見方があるのは、少々奇妙かもしれない。しかしながら、確率が「不確かさ」の定量的表現であったことを思い出そう。この2つの見方が不確かさに対して指しているのであれば、なんとなく許容されそうである。一般的な統計学及び機械学習は頻度主義の確率を採用している一方、ベイズ統計及びベイズ機械学習は主観確率を採用している。データ同化はベイズを用いるが、頻度主義を理解することの恩恵は非常に大きい。そこで本章では、頻度主義の観点と対比させながら、ベイズ機械学習を紹介することにした。

\subsection{頻度主義の確率と主観確率}
多くの人にとってなじみ深いのは頻度主義の確率であろう。たとえばサイコロの目が3となる確率を調べるたいとしよう。このとき、実際にサイコロを$n$回振って、そのうち$n_3$回3が出たならば、3が出る確率は$n_3/n$だと推測できる。以下は頻度主義の確率の形式張った説明である。
\begin{tcolorbox}[title=頻度主義の確率]
　事象$A$を生み得る実験を$n(\to \infty)$回行い、実際に$A$が$n_A$回起こったとき、${\rm Pr}(A)=n_A/n$と定義する。同様に確率変数$X$に関して$n(\to \infty)$回試行したとき、実現値$x$が$n_x$回起こったならば、${\rm Pr}(X=x)=n_x/n$と定義する。
\end{tcolorbox}
試行回数が$n \to \infty$となっている点に注意してほしい。当然ながら無限回の試行を実際に行うことは不可能なので、私たちは頻度主義の確率を厳密に求めることはできない。たとえ何万回と試行したとしても、その結果から得られる確率は推測値でしかない。\par
試行回数があまりにも少ないとき、推測結果はあまり信用できない。大げさな例だが、サイコロを$n=3$回振って、全て6が出たとする。この結果から「このサイコロは必ず6を出す」と見なしてしまうことは、当然ながら危険であろう。したがって、頻度主義の確率では十分な試行回数が必要になる(このことから、頻度主義を基盤にした機械学習がビッグデータを要する理由も見えてくる)。\par
一方で、主観確率のような考え方は案外私たちの生活の中でよく現れる。たとえば「このビジネスの成功確率は?」と聞かれたとき、私たちは「70\%です」と答えたりする。その確率は過去の実績(つまり実際の試行結果)から算出されたものかもしれないが、単に自分の自信度合いから導出されたものかもしれない。主観確率は後者の自信度合い的な考えに近い。\par
当然ながら自信度合いなんてものには個人差があり、客観性に欠ける(まさに主観)。数値で表現しているとは言え、主観確率はどこか定性的にも見える。ベイズ統計やベイズ機械学習は、この主観確率を存分に活用しているのだから、今の段階では不思議に思われるかもしれない。実際、数十年前までベイズ統計や主観確率は多くの統計学者から嫌われていた。しかし、今では「厳密ではないかもしれないが、役に立つ」と認識されている。\par
例えば「30年後の地球の平均気温が、今と比べて1℃高い確率は?」といった問題を考えてみよう。先ほどのビジネスに関する確率では過去の実績から頻度主義の確率を求められたかもしれないが、今回はそう上手くいかない。未来の話ゆえに一度の試行結果も与えられないためである。他方の主観確率は相変わらず「自信度合い」から導出できる(例えば30\%)。この30\%という数値が、エネルギー問題や世界情勢などを鑑みて導出されたものならば、主観とはいえ信頼できるかもしれない。少なくとも全く手を出せなかった頻度主義よりかは断然ましだろう。\par
このように、主観確率は客観性を捨てた分、有識者のドメイン知識を組み込みやすくしている。そして数学的厳密さを犠牲にすることで、現実の多くの問題において実利を与えてくれている。以下は主観確率の私なりの解釈である。
\begin{tcolorbox}[title=主観確率]
　有識者が主観的に決めた確率値。その正しさは有識者の知識に依存する(見当違いな確率値を設定された場合は、悲惨な結果を招く)。
\end{tcolorbox}
驚くべきことに、ベイズの定理(式(9)(10))は主観確率(つまり統計学と関係のないドメイン知識)とデータサイエンスを結びつけてくれる(後述)。

\subsection{頻度主義による線形回帰}
ここからは線形回帰を題材にして頻度主義による機械学習とベイズ機械学習を比較していく。なお、以後は前者を単に機械学習と呼ぶことにする。\par
まず機械学習の方を考えよう。いま、データセット$D=\{ (x_i, y_i)|i=1,...,N \}$を持っており、$y$を$ax+b$で表したいとする。つまり$x$を入力として$y$を推測したい訳であるが、機械学習の分野では入力の代わりに説明変数、推測対象のことを目的変数と言う。\par
さて、データセットは実験やセンシングなどで集められた結果だが、そこにはノイズが混在してしまう。一般的にノイズは目的変数にのみ含まれる。例えば実験に関するデータであれば、説明変数は実験条件で目的変数は実験結果になる。また、センシングデータであれば、説明変数は時刻で目的変数はセンサ値かもしれない。いずれの説明変数も設定しやすく、あまりずれることはない(図3)。本資料でも誤差やノイズは目的変数に対してのみ考慮する。

\begin{figure}[t]
\begin{center}
\includegraphics[width=7cm]{"fig3.png"}
\caption{適当に探してきた図。一般的に横軸(説明変数)のバラつきは考慮されないことがよく分かる。}
\end{center}
\end{figure}

機械学習の目的は説明変数と目的変数を繋ぐ数理モデルの学習であり、今回の場合はパラメータ$a$と$b$の学習である。皆様はすでに最小二乗法をご存じかもしれないが、本資料では確率論的に議論することにしよう。\par
まず、次節の表記と合わせるために、$\bm x=(x, 1)^{\rm T}$と$\bm w=(a, b)^{\rm T}$なるベクトルを定義する。すると$ax+b=\bm x^{\rm T}\bm w$となるので、線形回帰はベクトル$\bm w$を推定する問題だと考えられる。ただしいかなる$\bm w$においても、$y$と$\bm x^{\rm T}\bm w$が全てのデータで一致することはなく、
\begin{equation}
y_i=\bm x_i^{\rm T} \bm w + \epsilon_i
\end{equation}
をもって等式が成立する。ここで$\epsilon_i$は$y_i$と$\bm x_i^{\rm T} \bm w$の差分だが、機械学習では目的変数の誤差と見なす。ただし、あくまで差分だったことは覚えておいてほしい。例えば$\bm x=\bm x_i$のときの、真の値を$y_t$とし、そこに誤差$\xi_i$が含まれた結果$y_i=y_t+\xi_i$が得られたとする。この$\xi_i$は真の値からのずれなので、センサノイズなどに相当する真の誤差と言える。一方の$\epsilon_i$は式(25)より、
\begin{equation}
\epsilon_i=(y_t-\bm x^{\rm T}\bm w)+\xi_i
\end{equation}
となる。つまり、$\epsilon_i$は本来の誤差$\xi_i$に数理モデルのずれ$(y_t-\bm x^{\rm T}\bm w)$が加わったものと言える。\par
$\xi_i$は確率変数$\xi$のサンプリング結果であるとしよう。また、$\xi$の確率分布を$\mathcal{N}(0, \sigma^2)$とする。ここで$\sigma^2$はセンサノイズに関する分散である。センサであれば$\sigma^2$はカタログ等から推定可能だが、未知であることもある。一方で$\epsilon_i$も確率変数$\epsilon$の実現値であるとし、その確率分布を$\mathcal{N}(0, \sigma'^2)$と仮定する。式(26)より、$y_t$と$\bm x^{\rm T}\bm w$が近い値をとれば、つまり数理モデルが正しければ、$\epsilon_i$と$\xi_i$の差はなくなる。したがって、学習が上手くいくと考え、$\epsilon$に対して$\xi$と似た確率分布を仮定することは問題にならない。\par
目的変数のバラつきを表すために、$y$に関する確率変数$Y$を考える。式(25)より、確率変数$Y$の確率分布$p(Y|x, \bm w)$は$\mathcal{N}(\bm x^{\rm T}\bm w, \sigma'^2)$になる(正規分布の線形変換)。なお、$Y$の分布は$x$と$\bm w$に依存するため条件付確率$p(Y|x, \bm w)$とした。\par
ここまでの仮定より、データセット$D$は確率分布$\mathcal{N}(\bm x^{\rm T}\bm w, \sigma'^2)$からサンプリングされた結果ということになる。各データが独立にサンプリングされたとすると、$D$が得られる確率$L$は
\begin{equation}
L=\prod_i \mathcal{N}(Y=y_i|\bm x_i^{\rm T}\bm w, \sigma'^2)
=\prod_i \frac{1}{\sqrt{2\pi\sigma'^2}}{\rm exp}\left(
-\frac{(y_i-\bm x_i^{\rm T}\bm w)^2}{2\sigma'^2}
\right)
\end{equation}
となる。この$L$は$D$が得られる尤もらしさという意味で、尤度と呼ばれる。ただしこの尤度には未知数$\bm w$と$\sigma'^2$が含まれている。したがって、ここからは尤度関数$L(\bm w, \sigma'^2)$と呼ぶ。\par
当然ながら尤度関数の値は$\bm w$と$\sigma'^2$に依存する。低い尤度を与えるパラメータの場合、$D$が得られたという結果は稀であることを示す。逆に高い尤度の場合、$D$なる結果と辻褄が合う。したがって、尤度関数を最大とする$\bm w$と$\sigma'^2$を是とすると良さそうである。機械学習は詰まる所尤度関数の最大化問題と言える。ただし実際の計算では$L$の代わりに$-{\rm ln}L$の最小化を考える。式(27)より$-{\rm ln}L$は
\begin{equation}
-{\rm ln}L(\bm w, \sigma'^2)=\frac{N}{2}{\rm ln}\sigma'^2+\frac{N}{2}{\rm ln}(2\pi)+\frac{1}{2\sigma'^2}\sum_i (y_i-\bm x_i^{\rm T}\bm w)^2
\end{equation}
と求まる。上式が最小値となるとき、$-{\rm ln}L$のパラメータに関する偏微分はゼロになる。そこで式(28)を見返すと、第三項のみ$\bm w$に依存することに気付く。そのため、$\bm w$の最適値探査は、
\begin{equation}
E=\frac{1}{2}\sum_i (y_i-\bm x^{\rm T}\bm w)^2
\end{equation}
の最小化問題で済むことが分かる。これは正に二乗和誤差で、最小二乗法で利用されている評価関数である。最小二乗法では「$y$と$\bm x^{\rm T}\bm w$のずれを最小化させる」という幾何的解釈で説明されるが、その根底に正規分布という確率的仮定があったことは興味深い。また、式(29)で考える最小二乗法は暗に$\sigma'^2$の存在を無視していたことになる。場合によってはショックを受けたかもしれないが、実はそれほど罪深くはない。というのも最小二乗法に限らず頻度主義の機械学習の多くはバラつき$\sigma'^2$の存在を無視して議論しており、データと数理モデルが平均的にみて一致することのみ要求する。ちなみに式(29)に対して$\sigma'^2$の最適値を探査すると、結果は
\begin{equation}
\sigma'^2=\frac{1}{N}\sum_i (y_i-\bm x_i^{\rm T}\bm w)^2 \notag
\end{equation}
となる。これは線形回帰の結果$\bm x_i^{\rm T}\bm w$を平均値に見立てたデータ$y_i$の分散であり、パラメータ$\bm w$が推定された今となっては月並みな結果に過ぎない。\par
しかしながら、上記のような形で推測値のバラつきを評価できることは理解しておくべきであろう。世間では、「バラつき評価はベイズ機械学習の専売特許」と言う人が多いが、それは誤解である。単に、わざわざ頻度主義でバラつき評価をしないだけである。ただ、ベイズ機械学習の方がバラつき評価に向いていることは事実である。例えば図4のようにバラつきが$x$に依存するような場合、話は複雑になってくる。ここまでの議論では、$\sigma^2$や$\sigma'^2$は$x$に依存しないと考えてきた。依存するとなった場合、議論は初めからやり直しになる。また計算も複雑で、あまりやる気が起きない(私は経験したことがない)。一方で、この後すぐ紹介するベイズ機械学習では図4のようなバラつきであっても自然に対応可能である。それゆえバラつき評価も必要な場合はベイズ機械学習を利用することが一般的になった。\par
さて、ご存じの通り機械学習ではビッグデータが好まれる。これはひとえに式(29)、つまり誤差関数がデータに依存するためである。データ数が少なくなるにつれ、誤差関数に対する各データの寄与は上がる。仮に少数のデータしか集められず、かつそのデータに外れ値が含まれている場合、誤差関数は的外れな指標となってしまい、学習に失敗する。\par
同様のことを式(27)からも読み解ける。式(27)の最大化は、いわばデータセットが作った分布にフィッティングさせる処理である。データセットが作る分布は正に頻度主義的な確率分布であるため、データ数が少ないと信憑性は低い。安心して頻度主義確率を利用できるだけの、ビッグデータが必要になる訳である。

\begin{figure}[t]
\begin{center}
\includegraphics[width=5cm]{"fig4.png"}
\caption{バラつきが説明変数に依存する例。}
\end{center}
\end{figure}

\subsection{ベイズ機械学習による線形回帰}
\subsubsection{ベイズ機械学習の考え方}
頻度主義の線形回帰では、学習パラメータ$\bm w$は確定値として扱われていた。データのばらつきは誤差として認め、$\mathcal{N}(\bm x^{\rm T}, \sigma'^2)$に従うと考えた。ただし結局は式(29)の最小化問題に帰着させるので、分散を意識することは稀である。特別な処理を追加しない限り、機械学習は平均的に$y$が$\bm x^{\rm T}\bm w$で書き表されるということを教えてくれるのみである。\par
一方のベイズ機械学習では学習パラメータを確率変数と考える。例えば$\bm w$が$\mathcal{N}(\bm \mu, \Sigma)$に従う2次元確率変数である場合、$y$も確率変数で表され、その確率分布$p(Y|x)$は
\begin{equation}
p(Y|x)=\mathcal{N}(\mu_y, \sigma_y^2),~~~\mu_y=\bm x^{\rm T}\bm \mu,~~~\sigma_y^2=\bm x^{\rm T}\Sigma \bm x \notag
\end{equation}
となる(正規分布の線形変換)。誤差項をもって不確かさを表現していた前節の機械学習に対し、ベイズ機械学習は不確かさをパラメータに内包させる(したがって$\sigma'^2$の推定が不要になる)。そして、ある説明変数$x$のときの真の値を$y_t$としたとき、データは$\mathcal{N}(y_t, \sigma^2)$に従ってばらつく訳であるが、ベイズ機械学習は$\mu_y$を$y_t$に、$\sigma_y^2$を$\sigma^2$に一致するよう学習する。複雑な考察を行う分、ベイズ機械学習は上式のように$y$の不確かさも容易に扱える。当然ながらパラメータに関する確率分布は前もって与えられない。ベイズ機械学習の目的は正にパラメータの確率分布の推定である(図5)。

\begin{figure}[b]
\begin{center}
\includegraphics[width=15cm]{"fig5.png"}
\caption{線形回帰における頻度主義的機械学習とベイズ機械学習の解釈の違い。(a)頻度主義(b)ベイズ機械学習。}
\end{center}
\end{figure}

機械学習はデータセットの分布に一致するようパラメータを推定していた。その点パラメータの確率分布自体を推定することは、特徴的であると言える。しかしながら、私たちは如何にしてパラメータの確率分布を得られるだろうか。手元にあるのはデータセット$D$のみで、パラメータのサンプルデータなんてものはない(あるはずがない)。頻度主義アプローチで確率を求めることは不可能と言える。\par
そこで登場するのが主観確率である。ベイズ機械学習ではドメイン知識を駆使して学習パラメータの確率分布$p(\bm w)$を決めてしまう。しかしながら、これだけだとベイズ機械学習の価値はない。単に他の学問の知識を活用しただけであって、データサイエンス的な要素が全くない。ドメイン知識を活用しつつ、データセットを根拠に推定されたパラメータの確率分布、つまり$p(\bm w|D)$こそ私たちは知りたい。\par
以上を踏まえてベイズの定理を思い出そう。便宜的に再掲させて頂くと、ベイズの定理は
\begin{equation}
p(\bm w|D)\propto p(D|\bm w)p(\bm w) \notag
\end{equation}
のように書き表される。ここで$p(\bm w)$は主観確率、$p(\bm w|D)$はデータセットを根拠に含む確率であったが、以後はベイズ機械学習の慣習に従った呼び方を使う。まず$p(\bm w)$を統計的プロセスを施す前に与えられる確率という意味で、事前分布と呼ばれている。一方の$p(\bm w|D)$は事前分布に演算を施した結果という意味で、事後分布と呼ばれている。\par
残った$p(D|\bm w)$だが、これは以下のように展開できる。
\begin{equation}
p(D|\bm w)=p(\{ (x_i, y_i)|i=1,...,N \}|\bm w)=\prod_i p(x_i, y_i|\bm w)=\prod_ip(y_i|x_i, \bm w)p(x_i)=\prod_ip(y_i|x_i, \bm w). \notag
\end{equation}
なお、今回説明変数側の不確かさは無視しているので、$p(x_i)=1$とした。上式は正にデータセットに対する尤度に相当する(式(27))。\par
以上より、条件付確率から機械的に導出されたベイズの定理だが、ベイズ機械学習では事前分布、事後分布並びに尤度で構成されていることが分かった。\par
ベイズ機械学習の計算手順は以下の通りである。まず、$\bm w$の事前分布を決め、$\bm w$の取り得る値全てに対し尤度を計算する。そして$\bm w$の値毎に事前確率と尤度の積を計算すれば事後分布が得られる(最後は忘れずに事後分布を規格化させること)。ただし、式(27)では$\sigma'^2$が使われており、ベイズ機械学習では考えていなかった。$\sigma'^2$は元々のバラつき$\sigma^2$に、真の値$y_t$と数理モデルの差異が加わったものになる。仮に学習が成功し、後者が完全に一致するならば、$\sigma'^2$と$\sigma^2$も一致する。そこで本資料では、式(27)の$\sigma'^2$を$\sigma^2$に代えた尤度
\begin{equation}
L=\prod_i \mathcal{N}(Y=y_i|\bm x_i^{\rm T}\bm w, \sigma^2)
=\prod_i \frac{1}{\sqrt{2\pi\sigma^2}}{\rm exp}\left(
-\frac{(y_i-\bm x_i^{\rm T}\bm w)^2}{2\sigma^2}
\right)
\end{equation}
を使用する。また、$\sigma^2$はセンサノイズに相当するため、データ同化の問題では既知であることが多い。本資料でも既知であると考える。

\subsubsection{式展開を観察する}
まずはパラメータ$\bm w$の事前分布を
\begin{equation}
p(\bm w)=\frac{1}{2\pi|\Sigma|^{1/2}}{\rm exp}\left( -\frac{1}{2}(\bm w-\bm \mu)^{\rm T}
\Sigma^{-1}(\bm w-\bm \mu) \right) \notag
\end{equation}
と設定する。これは平均$\bm \mu$の正規分布であるから、事前に$\bm w$の値が$\bm \mu$付近であると考察したことに相当する。出力が分散$\sigma^2$の正規分布に従ってばらつくとき、データセットの尤度$p(D|\bm w)=L$は式(30)になる。したがってベイズの定理より、事後分布は
\begin{equation}
p(\bm w|D)=\frac{C}{2\pi|\Sigma|^{1/2}}{\rm exp}\left( -\frac{1}{2}(\bm w-\bm \mu)^{\rm T}
\Sigma^{-1}(\bm w-\bm \mu) \right)\frac{1}{(2\pi \sigma^2)^{N/2}}\prod_i {\rm exp}
\left( -\frac{(y_i-\bm x_i^{\rm T}\bm w)^2}{2\sigma^2} \right)
\end{equation}
と求まる。ここで$C$は規格化係数である。\par
パラメータの確率分布を調べたいというベイズ機械学習の目的は、これで達成したことになる。しかしながら、「どの値のときに事後分布が最大となるか」という情報は気になることもある。一般的に事後分布の最大値のことをMAPと言い、そのパラメータを推定することをMAP推定と言う。\par
MAP推定は当然ながら式(31)の最大値探査問題である。ただし、前節同様$-{\rm ln}p(\bm w|D)$の最小化問題を考える。細かい計算は省くが、$-{\rm ln}p(\bm w|D)$のうち$\bm w$に依存する項のみ残した評価関数$J$は
\begin{equation}
J=\frac{1}{2}(\bm w-\bm \mu)^{\rm T}\Sigma^{-1}(\bm w-\bm \mu)+\frac{1}{2\sigma^2}\sum_i(y_i-\bm x^{\rm T}\bm w)^2
\end{equation}
となる。第二項は$\sigma^{-2}$の重み付き二乗和誤差になっている。一方で第一項は事前分布時に設定した$\bm \mu$から$\bm w$が離れるほど大きな値を取るようになっている(このような測度をマハラノビス距離と言う)。そのため、MAP推定は二乗和誤差と事前分布からのずれを最小化させる最適値探査問題だと考えられる。\par
一部の方は事前分布(つまり主観確率)の利用にまだ抵抗があるかもしれない。主観確率の決め方によって解が変わってしまうのは、ときに信用できなく思えてしまう。確かに事前分布の設定が的外れであれば、第一項は足を引っ張ることになる。しかしながら、データ数$N$が多くなるにつれ第二項の割合は大きくなる。ビッグデータを用意できるならば、ベイズ機械学習の結果は事前分布に影響されにくくなるので、安心してもよい。逆に事前分布が的を得ている場合、第一項は学習を助けてくれる。もしもデータ数が少なく、しかもデータの中に外れ値が含まれている場合、頻度主義的に第二項は学習を妨げる。そのとき第一項は外れ値に敏感に反応しないよう働きかけてくれる。\par
この議論はMAP推定だけでなく確率分布自体にも言える。つまり、データ数が多くなれば事後分布は事前分布の影響を受けにくい。また、データ数が少ないとき、事後分布は事前分布のおかげで外れ値に対してロバストになる。

\subsubsection{式展開を観察する2}
先ほどの例をここでは別の視点で観察する。式(31)は正規分布の積なので、事後分布も正規分布となる。そこで式(31)を展開し、まずは
\begin{equation}
\frac{1}{2\pi|\Sigma|^{1/2}}{\rm exp}\left( -\frac{1}{2}(\bm w-\bm \mu)^{\rm T}
\Sigma^{-1}(\bm w-\bm \mu) \right)\frac{1}{(2\pi \sigma^2)^{1/2}}
{\rm exp}
\left( -\frac{(y_i-\bm x_i^{\rm T}\bm w)^2}{2\sigma^2} \right) \notag
\end{equation}
を計算してみる。これは1つ目のデータのみを学習に利用したときの事後分布に相当する。導出は省略するが、この結果は平均$\bm \mu_1$及び分散共分散行列$\Sigma_1$が
\begin{equation}
\bm \mu_1=\Sigma_1\left(\Sigma^{-1}\bm \mu+\frac{1}{\sigma^2}y_1\bm x_1 \right) \notag
\end{equation}
\begin{equation}
\Sigma_1=\left(\Sigma^{-1}+\frac{1}{\sigma^2}\bm x_1\bm x_1^{\rm T}\right)^{-1} \notag
\end{equation}
で与えられる。この確率分布$\mathcal{N}(\bm \mu_1, \Sigma_1)$を利用すると、式(31)の事後分布は
\begin{equation}
p(\bm w|D)=\mathcal{N}(\bm \mu_1, \Sigma_1)
\frac{C}{(2\pi \sigma^2)^{(N-1)/2}}\prod_{i=2}^N {\rm exp}
\left( -\frac{(y_i-\bm x_i^{\rm T}\bm w)^2}{2\sigma^2} \right) \notag
\end{equation}
と書き換えられる。上式の$i$が2から開始していることに注目してほしい。上式は正に、事前分布を$\mathcal{N}(\bm \mu_1, \Sigma_1)$とし、$i=2,...,N$のデータで学習したときの事後分布と捉えられる。従って、「初めに用意された事前分布から、一つのデータのみ用いて事後分布を計算し、それを次の学習の際に事前分布として利用する」、そういった逐次的なデータ処理が可能なことが分かる。この逐次的処理は主に2つの点で魅力的である。まず、データセット$D$を集めきるのに時間を要する場合、得られたデータから先んじて処理を施すことができる。データを集めきる前に分布の遷移を確認できることは、多くの場面で便利になってくる(ただしこのような計算手法は頻度主義の機械学習でも可能である。逐次的処理がベイズ機械学習の専売特許だと考えることは誤解である)。もう一つが、学習に利用したデータは消去しても構わない点である。$p(\bm W|D)$とう表記のせいか、「ベイズ機械学習は常に学習データを保存しておかなければならない」と誤解している人がたまにいる。しかしながら、上記の$\mathcal{N}(\bm \mu_1, \Sigma_1)$が得られれば、最早データ$(x_1, y_1)$は不要で、メモリ上から消去しても構わない。\par
逐次的処理でデータ$i$まで学習に利用し、正規分布$\mathcal{N}(\bm \mu_i, \Sigma_i)$が得られているとする。次のデータ$(x_{i+1}, y_{i+1})$を消費したとき、上記と同様に正規分布の平均及び分散は
\begin{equation}
\bm \mu_{i+1}=\Sigma_{i+1}\left(\Sigma_i^{-1}\bm \mu_i+\frac{1}{\sigma^2}y_{i+1}\bm x_{i+1} \right)
\end{equation}
\begin{equation}
\Sigma_{i+1}=\left(\Sigma_i^{-1}+\frac{1}{\sigma^2}\bm x_{i+1}\bm x_{i+1}^{\rm T}\right)^{-1}
\end{equation}
で更新される。このように、尤度関数と事前分布が正規分布で、パラメータに対する演算も線形演算子のみである場合、事後分布も必ず正規分布となる。この条件を満たすベイズ機械学習では確率的考察を全くせず、式(33)(34)を用いて只々機械的に学習を進めていくことができる(それゆえコーディングが容易)。

\subsubsection{pythonコード例}
式(33)(34)による線形回帰のpythonコードを実装していく。まず、データセットを以下のように用意した。\bigskip
\begin{python}
import numpy as np
import math

sigma2 = 0.1
data_x = np.random.rand(100)
data_y = 2.*data_x + 1. 

data_y += np.random.normal(0., math.sqrt(sigma2), size = 100)
\end{python}\bigskip
ここでsigma2は本資料中の$\sigma^2$に相当する。data\_xは説明変数($x$)であり、今回は[0,1]の一様乱数から個数100だけ生成した。data\_yは目的変数($y_t$)である。したがって、今回の例では$y=2x+1$を推定できれば学習成功ということになる。最後の行は目的変数にノイズを加える処理($y_t+\xi$)である。\par
次に事前分布を設定する。事前分布を正規分布とし、その平均と分散共分散行列を以下のように仮定する。\bigskip
\begin{python}
mu = np.array([[0.], [0.]])
Sigma = np.eye(2)
\end{python}\bigskip
ここでmu[0]は$y=ax+b$における$a$、並びにmu[1]は$b$を指す。上記コードより、事前分布は$\mathcal{N}(\bm0, I)$となる。\par
準備が整ったので、ここからは式(33)(34)に従いデータを処理していく。\bigskip
\begin{python}
for x, y in zip(data_x, data_y):
	bmx = np.array([[x], [1.]])
	new_Sigma = np.linalg.inv(np.linalg.inv(Sigma) + (bmx@bmx.T)/sigma2)
	new_mu = new_Sigma@(np.linalg.inv(Sigma)@mu+y*bmx/sigma2)

	Sigma = new_Sigma
	mu = new_mu
\end{python}\bigskip
ここでbmxは本資料中の$\bm x$に相当する。式(34)よりnew\_Sigmaを、式(33)よりnew\_muを計算した。最後にSigmaとmuの定義を更新している。これをデータの数だけ繰り返した。\par
以下は全コードを纏めたものである。これを実行したところ、最終的に
\begin{equation}
{\rm mu}=
\begin{bmatrix}
1.91 \\ 1.07
\end{bmatrix},~~~
{\rm Sigma}=
\begin{bmatrix}
0.0108 & -0.00566 \\
-0.00566 & 0.00395
\end{bmatrix} \notag
\end{equation}
を得た。これは平均的に見て$y=1.91x+1.07$と推定したことになるので、ある程度学習に成功したと言える。\bigskip
\begin{python}
import numpy as np
import math

sigma2 = 0.1
data_x = np.random.rand(100)
data_y = 2.*data_x + 1. 
data_y += np.random.normal(0., math.sqrt(sigma2), size = 100)

mu = np.array([[0.], [0.]])
Sigma = np.eye(2)

for x, y in zip(data_x, data_y):
	bmx = np.array([[x], [1.]])
	new_Sigma = np.linalg.inv(np.linalg.inv(Sigma) + (bmx@bmx.T)/sigma2)
	new_mu = new_Sigma@(np.linalg.inv(Sigma)@mu+y*bmx/sigma2)

	Sigma = new_Sigma
	mu = new_mu
\end{python}

\section{ノンパラメトリックベイズ機械学習}
\subsection{離散化されたノンパラメトリック確率分布の利用}
前章では事前分布と尤度に正規分布を採用していた。事前分布と尤度の積も正規分布に従うため、式(33)(34)のような正規分布のパラメータ($\bm \mu$と$\Sigma$)の更新アルゴリズムとして線形回帰を考えることができた。尤度が正規分布に従うことは多くの場合に言えることである(例えばセンサノイズ)。しかしながら、事前分布を正規分布と仮定することは如何であろうか。正規分布と仮定した結果、最終的に得られるパラメータのバラつきも正規分布と仮定したことになる。式(33)(34)の更新則が利用できるとはいえ、ときにこの仮定は学習失敗の原因となる。\par
それゆえ、「正規分布に限らず他のパラメトリック確率分布も吟味すべきである」は結論の一つとして言える(ただし正規分布と正規分布以外の積は正規分布にならないので、式(33)(34)の更新則は使えなくなることに注意)。しかしながら、一般的なパラメトリック確率分布のパラメータ数は少なく、分布の表現力は乏しい(1.4節)。この問題に関する解決策は様々提案されているが、本資料ではノンパラメトリック確率分布による解法を紹介する。\par
ではまず初めに、離散化されたノンパラメトリック確率分布を考えよう。これは式(21)のように書き表されるが、前章を踏まえた表記は
\begin{equation}
p(\bm w)=\sum_i^M p_i\delta(\bm w-\bm w_i) \notag
\end{equation}
の通りである。これは、$\bm w$の候補として$\{ \bm w_i|i=1,...,M \}$を選定し、それぞれの確率を$\{ p_i|i=1,...,M \}$としたことに相当する(図2(b)のイメージ)。\par
各$\bm w_i$の尤度は前章と変わらない。つまり式(30)を使うことができ、
\begin{equation}
L=\prod_j \frac{1}{\sqrt{2\pi\sigma^2}}{\rm exp}\left(
-\frac{(y_j-\bm x_j^{\rm T}\bm w_i)^2}{2\sigma^2}
\right) \notag
\end{equation}
となる。したがって、$\bm w_i$に関する事後分布は
\begin{equation}
p(\bm w_i|D)=p_iC\prod_j \frac{1}{\sqrt{2\pi\sigma^2}}{\rm exp}\left(
-\frac{(y_j-\bm x_j^{\rm T}\bm w_i)^2}{2\sigma^2}
\right)
\end{equation}
と求まる(ここで$C$は規格化係数)。これを離散化した各$\bm w_i$に対して求めればよい。

\subsubsection{pythonコード例}
では、上記の計算をpythonで実装してみよう。前章と同様に$y=2x+1$の学習を考える。\par
まず、$\bm w$空間を離散化する。$a$の範囲を[1,3)、$b$の範囲を[0,2)に限定し、それぞれ0.01の幅で離散化する。すると、$\bm w$の取り得る値は4万個になる(図6)。\bigskip

\begin{figure}[t]
\begin{center}
\includegraphics[width=12cm]{"fig6.png"}
\caption{$\bm w$の離散化の様子。}
\end{center}
\end{figure}

\begin{python}
import numpy as np

a = np.arange(1., 3., 0.01)
b = np.arange(0., 2., 0.01)

w = []
for ia in a:
	for ib in b:
		w.append(np.array([ia, ib]))
w = np.stack(w, axis = 0)
p = np.ones(len(w))/len(w)
\end{python}\bigskip
上記コード中のwはパラメータのリストであり、図6中の青点に相当する。また、pは各パラメータの事前分布で本資料中の$p_i$に相当する。今回は事前分布に一様分布を採用したため、\pythoninline{p = np.ones(len(w))/len(w)}とした次第である。\par
次に、式(35)に従ってデータ毎に尤度を掛けていく。\bigskip

\begin{python}
for x, y in zip(data_x, data_y):
	y_pred = w[:,0]*x + w[:,1]
	p *= np.exp(-(y-y_pred)**2/2/sigma2)/math.sqrt(2*np.pi*sigma2)

p /= np.sum(p)
\end{python}\bigskip
ここでy\_predは本資料中の$\bm x^{\rm T}\bm w$に相当する。また、\pythoninline{np.exp(-(y-y_pred)**2/2/sigma2)/math.sqrt(2*np.pi*sigma2)}は式(35)の
\begin{equation}
\frac{1}{\sqrt{2\pi\sigma^2}}{\rm exp}\left(
-\frac{(y_j-\bm x_j^{\rm T}\bm w_i)^2}{2\sigma^2}
\right) \notag
\end{equation}
である。従って、これをデータ毎に掛けられたpは最終的に事後分布になることが分かる(ただし最後の行で規格化する)。\par
これまでのコードを纏めたものを以下に記す。これを実際に実行すると、wの平均値は
\begin{equation}
{\rm w}=
\begin{bmatrix}
2.14 \\ 0.92
\end{bmatrix} \notag
\end{equation}
となった。\bigskip
\begin{python}
import numpy as np
import math

a = np.arange(1., 3., 0.01)
b = np.arange(0., 2., 0.01)

w = []
for ia in a:
	for ib in b:
		w.append(np.array([ia, ib]))
w = np.stack(w, axis = 0)
p = np.ones(len(w))/len(w)

data_x = np.random.rand(100)
sigma2 = 0.1
data_y = 2.*data_x + 1. + np.random.normal(0., math.sqrt(sigma2), size = 100)

for x, y in zip(data_x, data_y):
	y_pred = w[:,0]*x + w[:,1]
	p *= np.exp(-(y-y_pred)**2/2/sigma2)/math.sqrt(2*np.pi*sigma2)

p /=np.sum(p)
\end{python}

\subsection{アンサンブルによる表現}

\begin{figure}[b]
\begin{center}
\includegraphics[width=10cm]{"fig7.png"}
\caption{w=[1., 0.]における事後確率の遷移。}
\end{center}
\end{figure}

前述した通りノンパラメトリック機械学習は柔軟な分布の表現を可能にする。しかしながら、前節の手法は計算量の上で問題を抱えることがある。先ほどの例では$a$と$b$のパラメータをそれぞれ200分割した。それゆえ図6より$\bm w$の組み合わせは全4万通りになる。そしてそれぞれの$\bm w$に関して事後分布の計算を行う。つまり、4万回の繰り返し計算を要することになる。より一般的に書くと、$l$次元パラメータを各要素に対し$n$分割すると、離散化されたパラメータは総じて$n^l$通りある。事後分布の計算では$n^l$回の繰り返し計算を要する。\par
1.4節で述べた通り、離散数$n$が増加するにつれノンパラメトリック確率分布の表現力は増す(CAEの計算格子との類似性)。また、データ同化では$l$が非常に大きい値となりやすい。例えばI.C.の状態ベクトル$\bm f$が不確かな場合、$\bm f$を学習対象として扱う訳であるが、このときの$l$はCAE計算格子数だけの次元となる。従ってデータ同化の問題では$n^l$が非常に大きな値となってしまう。本節の目的は、この計算量を減らす方法の紹介である。\par
そこで、まずは図7のグラフを確認してほしい。これは前節の実装例におけるw=[1., 0.]の事後確率の遷移である。横軸は処理したデータの数であり、横軸がゼロのときの値は事前確率(つまり1/40000=2e-5)を示している。私たちはw=[2., 1.]が正解であると知っているため、[1., 0.]は的外れな推定であることも想像できる。そして実際、図7に示す通り$p([1., 0.]|D)$は非常に小さな値になっていく。少しのデータを処理した時点で「もう見込みは無いな」と思えるパラメータは$n^l$の繰り返し計算から省きたい。つまり、事後確率が低くなったパラメータを計算の途中で除外できるようなアルゴリズムを考えれば、計算コストを削減できそうである。\par
そこで登場するのがアンサンブルによって表現されたノンパラメトリック確率分布である。いま事前分布が式(22)のように
\begin{equation}
p(\bm w)=\frac{1}{M}\sum_i^M \delta(\bm w - \bm w_i) \notag
\end{equation}
で表されているとする。ここで$\bm w_i$はサンプル値で、$M$は重複を許すサンプル数である。ただし、以後はデータ同化の慣習に合わせて、各サンプルのことを粒子と呼ぶことにする。\par
粒子$\bm w_i$に対するデータ$(x_j, y_j)$の尤度を
\begin{equation}
\beta_{ij}=\frac{1}{\sqrt{2\pi\sigma^2}}{\rm exp}\left(-\frac{(y_j-\bm x_j^{\rm T}\bm w_i)^2}{2\sigma^2}\right) \notag
\end{equation}
と定義する。各粒子の確率は$1/M$であるため、データ$(x_j, y_j)$を処理した後の事後分布は$\beta_{ij}C/M$となる。ここで$C$は規格化係数であるが、$\sum_i \beta_{ij}C/M=1$より、直ぐに$C=M/\sum_j \beta_{ij}$だと分かる。よって、$\beta_{ij}/\sum_j \beta_{ij}$が低い場合というのは、図7のような今後見込みの無い粒子ということになる。従って今後はあまり計算したくない粒子ということになるが、何か$\beta_{ij}/\sum_j \beta_{ij}$に閾値を設けて継続可否を判断することはしない。その代わりに、$M$個の粒子を$\beta_{ij}/\sum_j \beta_{ij}$に従って再サンプリングする。このサンプリング結果は当然ながら事後分布に従う。ただし、有限個のサンプリングである以上、たとえ事後確率がゼロでなくても、一度もサンプリングされなかった粒子も現れる。そのため、事後確率の低い(つまり見込みの無い)粒子は優先的に無視されることになる。このようにして、アンサンブルによる確率分布は計算の省略を行うことができる。\par
以上の説明を聞いて、進化計算のアルゴリズムを思い出した方がいるかもしれない。確かに本手法は進化計算と非常に似ており、データ同化の論文中で度々比較されている。以下に、逐次的データ処理における事後分布の更新アルゴリズムを記す。\bigskip
\begin{itembox}[l]{アンサンブル表現によるノンパラメトリックベイズ機械学習}
\begin{enumerate}
\item 所望の事前確率分布$p(\bm w)$に従い、$M$個の粒子$\{ \bm w_i|i=1,...,M \}$をサンプリングする。
\item 各粒子$\bm w_i$に対して、一つのデータ$(x, y)$に関する尤度$\beta_i$を計算する。
\item 粒子を$\beta_i/\sum_i \beta_i$に従い$M$個だけサンプリングする(このとき、同じ粒子を複数回サンプリングしてもよい)。このサンプリング結果は事後分布のアンサンブル$\{ \bm w_i|i=1,...,M \}$になる。
\item 2.-3.を繰り返す。
\end{enumerate}
\end{itembox}\bigskip \par
しかしながら、このアルゴリズムだと上手く行かないことがある。アルゴリズムを眺めると、1.で生成された粒子$\{ \bm w_i|i=1,...,M \}$以外は、未来永劫登場しないことが分かる。3.は粒子の多様性を減らす一方で、今まで見たことのないようなパラメータ値$\bm w$を生成することはない(粒子の多様性が酷く低下することを退化と呼ぶ)。図8のような場合を考えよう。2次元のパラメータ空間に対して、正解は赤丸の値であったとする。一方で事前分布のサンプリング結果が青丸であった場合、上記アルゴリズムだと満足できる結果は得られないであろう。それゆえ各粒子がシフトできるような外部作用が欲しい。

\begin{figure}[b]
\begin{center}
\includegraphics[width=8cm]{"fig8.png"}
\caption{ノイズ付加がないと上手くいかない場合。赤丸は正解値。青丸は事前分布。}
\end{center}
\end{figure}

そのための手法として、よく分布に正規分布のノイズが付加される。つまり、分布を構成する各粒子$\bm w_i$に対して$\bm w_i \leftarrow \bm w_i + \bm \epsilon$の計算をする。ここで$\bm \epsilon$は多次元の正規分布である。このノイズ付加の結果、分布は変化してしまう。せっかくベイズ機械学習を根拠に導かれた分布にも関わらず、それを変形させてしまうことは理にかなってないようにも思える。確かにその指摘は尤もである。しかしながら、数値計算の都合上(つまり無限のサンプリングができないゆえに)、粒子の多様性を維持するためにどうしても必要なノイズと思って頂きたい(個人的に、このノイズは進化計算の突然変異に相当すると考えている)。せめて分布の期待値までも変わってしまわないように、ノイズの正規分布の平均はゼロと設定するのが一般的である。\par
ノイズを付加させた場合のアルゴリズムを以下に記す。\bigskip

\begin{itembox}[l]{アンサンブル表現によるノンパラメトリックベイズ機械学習}
\begin{enumerate}
\item 所望の事前確率分布$p(\bm w)$に従い、$M$個の粒子$\{ \bm w_i|i=1,...,M \}$をサンプリングする。
\item $\bm w_i \leftarrow \bm w_i + \bm \epsilon$。
\item 各粒子$\bm w_i$に対して、一つのデータ$(x, y)$に関する尤度$\beta_i$を計算する。
\item 粒子を$\beta_i/\sum_i \beta_i$に従い$M$個だけサンプリングする(このとき、同じ粒子を複数回サンプリングしてもよい)。このサンプリング結果は事後分布のアンサンブル$\{ \bm w_i|i=1,...,M \}$になる。
\item 2.-4.を繰り返す。
\end{enumerate}
\end{itembox}

\subsubsection{pythonコード例}
上記の計算をpythonで実装してみる。前章と同様に$y=2x+1$の学習を考える。\par
まず、$\bm w$の事前分布に、前章と同様の一様分布を採用する(つまり$a$は[1,3]の一様分布、$b$は[0,2]の一様分布)。粒子数M=1000としたときの、事前分布に従う粒子生成を以下に記す。\bigskip
\begin{python}
import numpy as np
import math

M = 1000
a = 1.+2.*np.random.rand(M)
b = 2.*np.random.rand(M)
w = np.stack((a, b), axis = 1)
\end{python}\bigskip
次に尤度計算とサンプリングのコードを示す。\bigskip
\begin{python}
for x, y in zip(data_x, data_y):
	w += np.random.normal(0., 0.01, (M, 2))

	y_pred = w[:,0]*x + w[:,1]
	beta = np.exp(-(y-y_pred)**2/2/sigma2)/math.sqrt(2*np.pi*sigma2)

	p = beta/np.sum(beta)
	w_index = np.random.choice(M, M, p = p)
	w = w[w_index]
\end{python}\bigskip
上記betaは各粒子の尤度を纏めた配列である。それゆえpは各粒子の事後確率であり、\pythoninline{np.random.choice(M, M, p = p)}で事後分布に従ったサンプリングを行っている。ただしサンプリング結果は粒子のインデックス番号なので、次の行で該当するパラメータを抽出した。また、繰り返し計算の最初に、wにノイズを加えている。\par
これまでのコードを纏めたものを以下に記す。これを実行したところ、wの平均は
\begin{equation}
{\rm w}=
\begin{bmatrix}
1.88 \\ 1.07
\end{bmatrix} \notag
\end{equation}
となった。\bigskip
\begin{python}
import numpy as np
import math

M = 1000
a = 1.+2.*np.random.rand(M)
b = 2.*np.random.rand(M)
w = np.stack((a, b), axis = 1)

data_x = np.random.rand(100)
sigma2 = 0.1
data_y = 2.*data_x + 1. + np.random.normal(0., math.sqrt(sigma2), size = 100)

for x, y in zip(data_x, data_y):
	w += np.random.normal(0., 0.01, (M, 2))

	y_pred = w[:,0]*x + w[:,1]
	beta = np.exp(-(y-y_pred)**2/2/sigma2)/math.sqrt(2*np.pi*sigma2)

	p = beta/np.sum(beta)
	w_index = np.random.choice(M, M, p = p)
	w = w[w_index]
\end{python}

\section{データ同化の前準備}
本章以降からようやくデータ同化の話に進む。ベイズ機械学習(2-3章)では線形回帰にしか触れていないが、それでも学ぶことは多かった。線形回帰以外の数理モデルであっても、2-3章の議論は転用できるためである。しかしながら、このままCAEを用いたベイズ機械学習(つまりデータ同化)に進んでしまうのは不親切であるため、ここでベイズ機械学習の一般性のある表記を紹介しておく。
\begin{tcolorbox}[title=ベイズ機械学習の一般的表記]
　説明変数を$\bm x=(x_1, x_2, ..., x_n)^{\rm T}$、目的変数を$\bm y=(y_1, y_2, ..., y_m)^{\rm T}$とし、数理モデル$\bm y=f(\bm x, \bm w)$を考える。ここで$\bm w$は関数$f$のパラメータをベクトルで纏めたものである。データセット$D=\{ (\bm x_i, \bm y_i)|i=1,...,N \}$があるとき、パラメータ$\bm w$を学習したい。\par
そこでベイズ機械学習の利用を考える。$\bm w$の事前分布として$p(\bm w)$を用意する。多次元の目的変数はノイズを受け、分散共分散が$\Sigma$の正規分布に従ってばらつく。各データが独立にサンプリングされたとき、$D$に関する尤度関数$p(D|\bm w)$は
\begin{equation}
p(D|\bm w)=\prod_i \frac{1}{(2\pi)^{m/2}|\Sigma|^{1/2}}{\rm exp}\left(
-\frac{1}{2}(\bm y_i - f(\bm x_i, \bm w))^{\rm T}\Sigma^{-1}(\bm y_i - f(\bm x_i, \bm w))
\right) \notag
\end{equation}
となる。従って事後分布はベイズの定理より
\begin{equation}
p(\bm w|D)=Cp(\bm w)\prod_i \frac{1}{(2\pi)^{m/2}|\Sigma|^{1/2}}{\rm exp}\left(
-\frac{1}{2}(\bm y_i - f(\bm x_i, \bm w))^{\rm T}\Sigma^{-1}(\bm y_i - f(\bm x_i, \bm w))
\right) \notag
\end{equation}
と求まる(ここで$C$は規格化係数)。
\end{tcolorbox}
2-3章と比べ、線形回帰の部分が$f(\bm x, \bm w)$に代わったこと、並びに尤度関数が多次元正規分布の積になったこと以外は同じであることが分かる。なお、多次元正規分布が使われるようになった理由は、目的変数$\bm y$が多次元になったためである。

\subsection{システムモデルと観測モデル}
\subsubsection{システムモデル}
ここで具体的な話に戻し、データ同化における$f(\bm x, \bm w)$の在り方を議論していく。ところで、CAEは支配方程式を満たす関数(連続体力学では場と言う)の求解といえる。つまり、位置座標$\bm r$と時刻$t$における物理量$u(\bm r, t, \bm w)$をCAEでは求めている。ここで$\bm w$はB.C.などのCAEに必要なパラメータであり、CAE実行時にいくつかパラメータを設定すると思われるが、それらをベクトルとして纏めたものと考えて頂ければ結構である(「B.C.はノイマンもしくはディリクレ」といった一見数値で表せないような場合でも、「ノイマン=1、ディリクレ=0」のように離散値でラベル付けすればよい)。\par
CAEは格子法と粒子法に大別できるが、どちらも物理場$u(\bm r, t, \bm w)$を離散化して求めている。つまり、$u(\bm r, t, \bm w)$を陰関数の形ではなく、状態ベクトルとして求める。例えば格子法の場合、格子毎に物理量$u_{ij}$が定義されているが(図9)、これを一つに纏めたベクトル
\begin{equation}
{\bm u}=(u_{11}, u_{12}, ..., u_{1N}, u_{21}, ..., u_{2N}, ..., u_{MN})^{\rm T} \notag
\end{equation}
は、正にパラメータ$\bm w$における時刻$t$の物理場と言える(このような状態ベクトルによる表現は粒子法でも可能である)。なお、複数の物理量($u$と$v$)を扱う場合は、
\begin{equation}
{\bm u}=(u_{11}, v_{11}, u_{12}, v_{12}, ..., u_{1N}, v_{1N}, u_{21}, v_{21}, ..., u_{2N}, v_{2N}, ..., u_{MN}, v_{MN})^{\rm T} \notag
\end{equation}
のように重ねればよい。

\begin{figure}[t]
\begin{center}
\includegraphics[width=8cm]{"fig9.png"}
\caption{格子法における物理場の表現。それぞれの四角は計算格子で、$u_{ij}$はその計算格子における物理量を表している。}
\end{center}
\end{figure}

当然ながら、CAEは時間方向に対しても離散化する。時刻$t$の状態ベクトル$\bm u_t$を与えたとき、次時間ステップの状態$\bm u_{t+\Delta t}$はCAEのアルゴリズムより求まる。したがって、CAEのことを「パラメータ$\bm w$に従って、現時刻の状態ベクトル(説明変数)から次時刻の状態ベクトル(目的変数)を求める数理モデル」と定義できる。そこで、この機能を
\begin{equation}
\bm u_{t+\Delta t}=f(\bm u_t, \bm w)
\end{equation}
で表現できることにする。\par
式(36)こそ正にCAEの数理モデル表現である。しかし残念ながら、データ同化においてこの表現はあまり用いられない。例えばパラメータが所与のとき、式(36)による$\bm u_t$から$\bm u_{t+\Delta t}$の更新は確定的である。同様にI.C.として$\bm u_0$を与えたとき、次時刻の状態ベクトル$\bm u_1$も一つの値に決まる。また、次の状態$u_2$やその次の$u_3$も一つの値に決まる。つまりI.C.の$\bm u_0$が与えられれば、任意のステップの状態ベクトル$\bm u_{n\Delta t}$は一意に決まり、式(36)より
\begin{equation}
\bm u_{n\Delta t} =f(\bm u_{(n-1)\Delta t}, \bm w)=f(f( ... f(\bm u_0))\bm w)=F(\bm u_0, \bm w) \notag
\end{equation}
のような数理モデルで書き表すことができる。しかしながら、データ同化を用いる問題では、I.C.も未知であることが多い。そのため上式の$\bm u_0$もパラメータとして扱う必要がある。\par
そこで$\bm u_0$と$\bm w$を改めて$\bm x_0$に纏め、上式を$\bm u_{n\Delta t}=F(\bm x_0)$に書き換える。更に、状態ベクトル$\bm u$とパラメータ$\bm w$を纏めたベクトルを$\bm x$と定義すれば、上式は$\bm x_{n\Delta t}=F(\bm x_0)$と書き換えられる。ただし、
\begin{equation}
\bm x_{n\Delta t}=F(\bm x_0)=
\begin{bmatrix}
f(f(...f(\bm u_0), \bm w) \\ \bm w
\end{bmatrix}=
\begin{bmatrix}
\bm u_{n\Delta t} \\ \bm w
\end{bmatrix}\notag
\end{equation}
であり、$\bm w$は何ら作用を受けないとする。\par
このように、物理量とパラメータを纏めたベクトルをデータ同化では好んで利用する。この慣習に倣えば、式(36)の数理モデルは
\begin{equation}
\bm x_{t+\Delta t}=F(\bm x_t) \notag
\end{equation}
に書き換えられる。ちなみに$\bm x$という表記は多くのデータ同化の書籍に倣った次第である。これまで説明変数に$\bm x$を使ってきた分、以後は意味が変わるこに注意頂きたい。上式中の$\bm x$は数理モデルのパラメータ$\bm w$も含んでいる。そのため、これを説明変数と呼ぶことは難しいかもしれない。実際、データ同化の書籍では説明変数や目的変数といった言葉を用いない。単純に状態ベクトル$\bm x$の更新として扱う(無理に言うなら$\bm x_t$が説明変数で$\bm x_{t+\Delta t}$が目的変数)。\par
さて、繰り返しになるが上式の$F$はCAEが担う。データ同化は最終的に実観測データとすり合わせを行うが、たとえ現在の状態ベクトル$\bm x_t$が正しかったとしても(つまり正しい物理場とパラメータを用意できたとしても)、解析結果$\bm x_{t+\Delta t}$が正しいとは限らないことを、私たちは知っている。このずれは、支配方程式や解析手法そのものに問題があるときに発生する(データ同化は気象学の領域から発展してきたが、この分野では特にあり得る)。したがって、データ同化では上式の代わりに以下の数理モデルを考える。これをデータ同化の分野では特別にシステムモデルと呼ぶ。
\begin{tcolorbox}[title=データ同化のシステムモデル]
\begin{equation}
\bm x_{t+\Delta t}=F(\bm x_t)+\bm v_t
\end{equation}
\end{tcolorbox}
ここで$\bm v_t$はシステムノイズと言い、前述のずれに相当する。$\bm v_t$の値は理論的に解くことができそうだが、一般的に不確かなものとして確率変数で考える(それゆえノイズという言われ方をしている)。個人的に、気象学の色が濃く出た結果、システムノイズを確率変数と考えるようになったと思っている。流体力学によると、ある程度微視的に見た流れの中には、様々な方向の渦が多数存在している。大きな計算格子ではこれら渦の作用を表せないので、特にラグランジュ形式のCFDではランダムな作用を別途与える。これは式中で見れば正にシステムノイズに相当する。\par
とは言えデータ同化はCFD以外でも利用する訳なので、そのときもランダムなシステムノイズを設定することに抵抗を感じるかもしれない。しかしながら、私はシステムノイズを加えるならいつでもランダムな確率変数にすることをお勧めする。このシステムノイズは解析値のずれと説明したが、別の見方をすれば3.2節の後半で登場したノイズに相当する。つまり、粒子の多様性を維持するのにシステムノイズは上手く働いてくれる。後ほど紹介する粒子フィルタやそれに近い手法では、逆にこういった利点を求めてシステムノイズを与えることが多い。\par
さて、システムノイズのバラつき加減は、流体力学の例のように根拠をもって設定されることもあるが、実際は解析者が恣意的に決めることの方が多い。バラつき加減(例えば分散値)をハイパーパラメータとして考え、データ同化の成否をもとに調整することになる(なお、システムノイズの確率分布には正規分布がよく採用されている)。

\subsubsection{観測モデル}

\begin{figure}[t]
\begin{center}
\includegraphics[width=12cm]{"fig10.png"}
\caption{観測モデルについて。}
\end{center}
\end{figure}

私達が物理実験をするとき、まずは興味のある物理システムを実験装置内で構築し、センシングするのが一般的である。この実験装置内は物理場$u(\bm r, t)$なる状態にあるかもしれないが、この全ての情報をセンシングできることは稀である。そのため、センサデータと物理場の情報には乖離がある。情報という観点では「センサデータは物理場に加工が施されたもの」とも言える。\par
本資料を通して教師データの代表例にセンサデータを挙げていた。また、当然ながらCAEは物理場の解析を行う。つまり、センサデータ$\bm y$と状態ベクトル$\bm x$の間にも乖離があるため、両者を繋ぐ(いわゆる加工を施す)モデルが必要になる(図10)。このようなモデルを観測モデルと言う。\bigskip
\begin{itembox}[l]{観測モデルの例1}
　CAE側の状態ベクトルを$\bm x=(x_1, x_2, x_3, x_4, x_5, w_1, w_2)^{\rm T}$とする。ここで$x_i$は物理量、$w_i$はパラメータとする。従って、これは計算格子数が5個の解析に相当する。このうちセンサは$x_2$と$x_4$を測るものとする($y=(x_2, x_4)^{\rm T}$)。スパースな測定ゆえに状態ベクトルとセンサデータには乖離がある。\par
　$\bm x$から$\bm y$を得るには以下のように線形変換を施せばよい。
\begin{equation}
\bm y=H\bm x, ~~~
H=
\begin{bmatrix}
0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 \\
\end{bmatrix} \notag
\end{equation}
上式は観測モデルのほとんどを成している。しかしながら、実際のセンサデータにはノイズが含まれていること、並びにCAE結果である$\bm x$が必ずしも正しいとは言えないことより、両辺にずれが存在する。ずれ$\bm w$を含めた表記
\begin{equation}
\bm y=H\bm x+\bm w \notag
\end{equation}
を観測モデルと言う。また、この$\bm w$を観測ノイズと言う。これは式(26)の$\epsilon$に相当する。従ってこの観測ノイズも後ほど確率変数として扱われる。式(26)中の$\xi$がセンサノイズに相当することから、観測ノイズのバラつき加減にセンサノイズの誤差を設定することは、厳密にいえば誤りである。しかしながら、CAE結果が正しいと仮定して、観測ノイズ=センサノイズとすることも多い(実際に2章のベイズ機械学習では$\sigma'^2 \leftarrow \sigma^2$としている)。
\end{itembox}
\begin{itembox}[l]{観測モデルの例2}
　CAEの状態ベクトルを$\bm m=(m_1, m_2, m_3, m_4, m_5, w_1, w_2)^{\rm T}$とする。ここで$m_i$は各計算格子の質量(密度と計算格子体積の積)である。また、センサデータ$y$は物理システムの総重量であるとする。このとき、$y$と$\bm m$の関係は、観測ノイズを含めた形で
\begin{equation}
y=H\bm x+\bm w,~~~ H=
\begin{bmatrix}
1 & 1 & 1 & 1 & 1 & 0 & 0
\end{bmatrix}\notag
\end{equation}
と表記できる。このように、センサデータがシステム全体に関する情報であってもよい。
\end{itembox}
\begin{itembox}[l]{観測モデルの例3}
　CAE側の状態ベクトルを$\bm v=(v_1, v_2, v_3, v_4, v_5, w_1, w_2)^{\rm T}$とする。ここで$\bm v_i$は各計算格子の速さである。一方のセンサデータ$y$は計算格子3の運動エネルギーを測定する場合、両者の関係は
\begin{equation}
y=H(\bm v)+\bm w,~~~H(\bm v)=\frac{1}{2}mv_3^2 \notag
\end{equation}
となる。このように、非線形な変換を観測モデルとして採用してもよい。
\end{itembox}\bigskip \\
以上が観測モデルの例である。なお、例1や2では要素の抽出として線形変換を明記していたが、例3のように省略して書いてしまうことも多い。以下は観測モデルの一般的な表記である。
\begin{tcolorbox}[title=データ同化の観測モデル]
\begin{equation}
\bm y_t=H(\bm x_t)+\bm w_t
\end{equation}
\end{tcolorbox}

\subsection{非逐次型と逐次型のデータ同化}
前節でシステムモデルと観測モデルを学んだ。そこで、本章の初めにベイズ機械学習の一般的表記を紹介したが、これをシステムモデルと観測モデルによる表現に書き換えてみよう。ただし、データ同化には非逐次型と逐次型の2種類に大別できる。詳細は後述するが、今は「データを得る度に確率分布を更新する方を逐次型と言う」だけの認識で十分である。つまり、逐次型は式(33)(34)の更新的考えに似ている。

\subsubsection{非逐次型データ同化}
非逐次型データ同化の例は5章で紹介する。以下は非逐次型データ同化におけるベイズ機械学習の考え方である。なお、非逐次型データ同化ではシステムノイズを無視することが多い。本資料でもそれに倣うことにした。
\begin{tcolorbox}[title=非逐次データ同化]
　状態ベクトルの時系列を、$\{ \bm x_t|t=1,...,T \}$、同時刻のセンサデータを$\{ \bm y_t|t=1,...,T\}$で表す。ここで$\bm x_t$はシステムモデル
\begin{equation}
\bm x_{t+1}=F(\bm x_t) \notag
\end{equation}
に従い時間発展し、$\bm y_t$と$\bm x_t$の間には
\begin{equation}
\bm y_t=H(\bm x_t)+\bm w_t \notag
\end{equation}
の関係がある。パラメータを要素に含む$\bm x_t$はベイズ機械学習において確率変数として扱われる。また、$\bm y_t$も観測ノイズがあるため確率変数である。\par
　初期時刻の$\bm x$を$\bm x_0$、$\bm x_0$の初期分布(つまり事前分布)を$p(\bm x_0)$とする。$\bm x_0$が所与のとき$\{ \bm x_t|t=1,...,T \}$が得られたとするならば、センサデータ$Y=\{ \bm y_t|t=1,...,T\}$の尤度$p(Y|\bm x_0)$は
\begin{equation}
p(Y|\bm x_0)=\prod_t \frac{1}{(2\pi)^{m/2}|\Sigma|^{1/2}}{\rm exp}\left(
-\frac{1}{2}(\bm y_t-H(\bm x_t))^{\rm T}\Sigma^{-1}(\bm y_t-H(\bm x_t))
\right) \notag
\end{equation}
となる。したがって$\bm x_0$の事後分布は
\begin{equation}
p(\bm x_0|Y)=Cp(\bm x_0)
\prod_t \frac{1}{(2\pi)^{m/2}|\Sigma|^{1/2}}{\rm exp}\left(
-\frac{1}{2}(\bm y_t-H(\bm x_t))^{\rm T}\Sigma^{-1}(\bm y_t-H(\bm x_t))
\right)
\end{equation}
で求まる(ここで$C$は規格化係数)。
\end{tcolorbox}
上記の$\bm x_0$にはB.C.や物性値、並びにI.C.の情報が含まれている。つまり、表1の学習対象の全てを表すベクトルな訳であり、その事後分布(式(39))は正に所望の学習結果と言える。\par
このように、非逐次型データ同化は一般的なベイズ機械学習となんら変わらない。ただし、$\bm x_0$の次元は一般的な機械学習において見られないほど大きいこともあり、学習結果の精度や計算コストの面で苦労することがある。

\subsubsection{逐次型データ同化}
逐次型データ同化の例は6章で紹介する。以下は逐次型データ同化におけるベイズ機械学習の考え方である。なお、逐次型データ同化には平滑化という技術があるが、本資料では紹介しない。今後も平滑化なる手法が無いものとした説明になっていることにご留意頂きたい。\par
逐次型データ同化では次時刻のセンサデータまでしか考えない。初期時刻の状態ベクトルを$\bm x_0$とし、次時刻の状態ベクトルを$\bm x_1$とする。また、時刻1のときのセンサデータを$\bm y_1$とする。\par
$\bm x_0$が所与のとき、$\bm x_1$の条件付確率$p(\bm x_1|\bm x_0)$はシステムモデル$\bm x_1=F(\bm x_0)+\bm v_1$より求まる(例えば$\bm v_t$が$\mathcal{N}(\bm 0, \Sigma_v)$に従うとき、$p(\bm x_1|\bm x_0)$に関する確率分布は$\mathcal{N}(F(\bm x_0), \Sigma_v)$となる)。したがって、$\bm x_0$に関する確率分布$p(\bm x_0)$を用意すれば、$\bm x_0$と$\bm x_1$の同時確率分布$p(\bm x_0, \bm x_1)$は$p(\bm x_1|\bm x_0)p(\bm x_0)$より求まる。この確率を更に$\bm x_0$に関して積分すれば、$\bm x_1$に関する周辺確率$p(\bm x_1)$が得られる。逐次型データ同化ではこの$p(\bm x_1)$を事前分布として扱う。そうすれば状態ベクトル$\bm x_1$に対する$\bm y_1$の尤度$p(\bm y_1|\bm x_1)$は
\begin{equation}
p(\bm y_1|\bm x_1)=\frac{1}{(2\pi)^{m/2}|\Sigma|^{1/2}}{\rm exp}\left(
-\frac{1}{2}(\bm y_1-H(\bm x_1))^{\rm T}\Sigma^{-1}(\bm y_1-H(\bm x_1))
\right) \notag
\end{equation}
より求まり、$\bm x_1$の事後分布は
\begin{equation}
p(\bm x_1|\bm y_1)=Cp(\bm x_1)\frac{1}{(2\pi)^{m/2}|\Sigma|^{1/2}}{\rm exp}\left(
-\frac{1}{2}(\bm y_1-H(\bm x_1))^{\rm T}\Sigma^{-1}(\bm y_1-H(\bm x_1))
\right) \notag
\end{equation}
となる(ここで$C$は規格化係数)。\par
次の時刻のセンサデータ$\bm y_2$が得られたとき、$\bm x_1$の分布に上式の$p(\bm x_1|\bm y_1)$を利用し、同様に$p(\bm x_2)$の計算、そして事後分布$p(\bm x_2|\bm y_2)$を計算する。これを繰り返す処理が正に逐次型データ同化である。
\begin{tcolorbox}[title=逐次型データ同化]
　状態ベクトル$\bm x_{t-1}$に関する確率分布を$p(\bm x_{t-1})$とする。$\bm x_{t-1}$が所与のときの$\bm x_t$に関する確率分布$p(\bm x_t|\bm x_{t-1})$をシステムモデル
\begin{equation}
\bm x_t=F(\bm x_{t-1})+\bm v_t \notag
\end{equation}
より求める。すると$\bm x_{t-1}$と$\bm x_t$の同時確率$p(\bm x_t, \bm x_{t-1})$を周辺化することで、$p(\bm x_t)$が求まる。これを事前分布として利用する。\par
　時刻$t$におけるセンサデータを$\bm y_t$とする。この尤度$p(\bm y_t|\bm x_t)$は
\begin{equation}
p(\bm y_t|\bm x_t)=\frac{1}{(2\pi)^{m/2}|\Sigma|^{1/2}}{\rm exp}\left(
-\frac{1}{2}(\bm y_t-H(\bm x_t))^{\rm T}\Sigma^{-1}(\bm y_t-H(\bm x_t))
\right) \notag
\end{equation}
であるため、$\bm x_t$の事後分布は
\begin{equation}
p(\bm x_t|\bm y_t)=Cp(\bm x_t)\frac{1}{(2\pi)^{m/2}|\Sigma|^{1/2}}{\rm exp}\left(
-\frac{1}{2}(\bm y_t-H(\bm x_t))^{\rm T}\Sigma^{-1}(\bm y_t-H(\bm x_t))
\right)
\end{equation}
となる(ここで$C$は規格化係数)。式(40)を利用して更に$p(\bm x_{t+1})$を計算し、上記の処理を繰り返す。
\end{tcolorbox}
上記処理より、最終的に学習された確率分布$p(\bm x_T)$が得られる。式(40)の事後分布を次時刻で事前分布として扱う点は、2章で紹介した更新的アルゴリズムに似ている。\par
逐次型データ同化で最も特徴的なのは、やはり更新があることだろう。発展的な手法の多くは、更新のタイミングに追加の処理を施すことで、データ同化の性能を上げている。こういった余地がある分、逐次型データ同化の方が柔軟的だと個人的に思っている。\par
しかしながら、一度にデータを処理しないゆえの欠点も存在する。式(39)と(40)を見比べたとき、非逐次型データ同化は初期の$\bm x_0$の学習をしていること、そして逐次型データ同化は最終時刻$\bm x_T$の学習をしていることに気付く。システムモデルを用いれば$\bm x_0$の確率分布から$\bm x_T$の確率分布は求まるので、$\bm x_T$に関してしか分からない点で逐次型データ同化は劣っていると言える。逐次型データ同化はI.C.の不確かさに関しては何も教えてくれないことになるので、問題によっては不便に感じるかもしれない。また、逐次型データ同化では時間経過とともにパラメータ$\bm w$の分布も変わることになる。そのため、推測された物理量$\bm u_t$の時間発展も物理的に不自然な挙動を示す(図16)。最終時刻の$\bm x_T$が正しければ問題ないことも多いが、この不自然さはときに逐次型データ同化を選ばない理由となる。

\subsection{Lorenz63モデルの学習データ}
\begin{figure}[b]
\begin{center}
\includegraphics[width=9cm]{"fig11.png"}
\caption{Lorenz63モデルの生成データ(観測ノイズ込み)。}
\end{center}
\end{figure}

次の章からデータ同化について本格的に議論していく。具体的な理解を促すため、pythonコードによる実装例を紹介することにした。そこで、具体的なシミュレーション問題が必要になる訳だが、本資料ではLorenz63を採用する。\par
Lorenz63モデルは3つの変数$(x, y, z)$と3つのパラメータ$(p, r, b)$からなる、
\begin{equation}
\frac{dx}{dt}=-p(x-y) \notag
\end{equation}
\begin{equation}
\frac{dy}{dt}=-xz+rz-y \notag
\end{equation}
\begin{equation}
\frac{dz}{dt}=xy-bz \notag
\end{equation}
で表されるモデルである。ここで、本資料では原著に従い$p=28$、$r=10$、$b=8/3$とした。そして時間方向に関して離散化し、
\begin{equation}
x_t=x_{t-\Delta t} -p(x_{t-\Delta t}-y_{t-\Delta t})\Delta t \notag
\end{equation}
\begin{equation}
y_t=y_{t-\Delta t}+(-x_{t-\Delta t}z_{t-\Delta t}+rz_{t-\Delta t}-y_{t-\Delta t})\Delta t \notag
\end{equation}
\begin{equation}
z_t= z_{t-\Delta t}+(x_{t-\Delta t}y_{t-\Delta t}-bz_{t-\Delta t})\Delta t \notag
\end{equation}
なる更新式を作った。時間刻みは0.01とした。\par
本資料では3つのパラメータを既知とし、$(x, y, z)$の初期値(1, 0, 0)のみ未知であるとする。また、$(x, y, z)$を直接観測できるとし、観測ノイズは$\mathcal{N}(\bm 0, 4I)$に設定した。学習データに関しては以上の条件のもと生成した(図11)。以下に生成データを出力する関数を示す。引数のnoiseがFalseのときは、結果に観測ノイズを加えないことにする。また、関数の出力は2次元配列で、時刻1以降の結果である(行数はtime\_step、列数は3)。\bigskip
\begin{python}
import numpy as np

def Lorenz63(x0=1., y0=0., z0=0., time_step = 500、noise = True):
	p = 10.
	r = 28.
	b = 8./3.
	dt = 0.01

	x = np.zeros(time_step+1); x[0] = x0
	y = np.zeros(time_step+1); y[0] = y0
	z = np.zeros(time_step+1); z[0] = z0

	for t in range(1, time_step+1):
		x[t] = x[t-1] + dt*(-p*x[t-1]+p*y[t-1])
		y[t] = y[t-1] + dt*(-x[t-1]*z[t-1]+r*x[t-1]-y[t-1])
		z[t] = z[t-1] + dt*(x[t-1]*y[t-1]-b*z[t-1])

	data = np.stack((x, y, z), axis = 1)
	if noise:
		data += np.random.normal(0., 2., size = data.shape)

	return data[1:]
\end{python}

\section{非逐次型データ同化}
\subsection{4次元変分法}
代表的な非逐次型データ同化として4次元変分法がある。4次元変分法の事後分布推定は正に4.2.1節の通りである。ただし、4次元変分法では式(39)のMAP推定まで考えることが多い。\par
そこで、式(39)の最大値探査問題の代わりに、$-{\rm ln}p(\bm x_0|Y)$の最小化問題を考える。$-{\rm ln}p(\bm x_0|Y)$のうち、$\bm x_0$に依存する項のみを残した評価関数$J(\bm x_0)$は以下の通りになる。
\begin{tcolorbox}[title=4次元変分法におけるMAP推定]
\begin{equation}
J(\bm x_0)=\frac{1}{2}\sum_t (\bm y_t-H(\bm x_t))^{\rm T}\Sigma^{-1}(\bm y_t-H(\bm x_t))-{\rm ln}p(\bm x_0)
\end{equation}
\end{tcolorbox}
上式の第一項はセンサデータに対する二乗和誤差に似ている。この解釈は正しく、マハラノビス距離における二乗和誤差と言われている。また、第二項は事前確率が高い$\bm x_0$を是とした評価関数である。この評価関数は式(32)と非常に似ており、2.3.2節での議論はここでも使える。つまり、データ数が多くなると事前分布の寄与は小さくなる。一方でデータに外れ値が含まれている場合、事前分布の存在は学習のロバスト性を向上させる。もしも$\bm x_0$に関して何ら知見がなければ、第一項のみの学習、つまり頻度主義的な機械学習を行えばよい。\par
式(41)の最小化は何となく簡単に見えるが、計算コストの面で意外と大変だったりする。一般的に、データ同化で扱うベクトル$\bm x$は次元が大きい(計算格子数だけ必要になることもある)。従って基本的に最適化には勾配法が使われるが、高次元のベクトルに対する微分を計算するのはときに大変である。勾配を求める際は、アジョイント法もしくは微分可能プログラミングによる実装が必要になるかもしれない。

\subsubsection{pythonコード例}

\begin{figure}[t]
\begin{center}
\includegraphics[width=9cm]{"fig12.png"}
\caption{4次元変分法の結果と正解値の比較。(1, 0, 0)の結果が正解値(ただし観測ノイズが含まれている)。(-0.3, 1.5, -1.8)の結果が4次元変分法による推定結果。}
\end{center}
\end{figure}

4次元変分法でLorenz63モデルの初期値$\bm x_0=(x_0, y_0, z_0)$を推定する。今回は事前分布に関する知識はなく、式(41)中の第一項のみを考えるとする(つまり頻度主義的な学習)。観測ノイズを$\mathcal{N}(\bm 0, 4I)$としたとき、式(41)は
\begin{equation}
J(\bm x_{0})=\frac{1}{8}\sum_i|\bm y_t-\bm x_t|^2 \notag
\end{equation}
に書き換えられる。
ここで$\bm y_t$は時刻$t$の観測データ、$\bm x_t$は初期値を$\bm x_0$としたときの推定値である。\par
$\bm x_0$に関する$J$の微分$\nabla J$は差分法で求める。また、連続値最適化には最急降下法を用いる。つまり探索点は$\bm x_0 \leftarrow \bm x_0 - \alpha \nabla J$に従い更新する。ここで$\alpha$は緩和係数である。\par
まず上式の$J$を返す関数を定義した。なお、上式では各データに対し和を取っているが、今回は評価関数値の発散を防ぐために平均値とした。\bigskip
\begin{python}
import numpy as np

def J(x, y):
	return np.mean((y-x)**2)/8.
\end{python}\bigskip
次に、学習データを生成する。コード中のyは本資料の$\{y_t|t=1,...,T\}$に相当する。また、pred\_initは初期値の推定値にあたる。後の反復計算でこの配列を更新していく。dhは差分計算時のステップ幅で、alphaは緩和係数である。\bigskip
\begin{python}
y = Lorenz63()

pred_init = np.array([0., 0., 0.])
dh = 0.001
alpha = 1e-3
\end{python}\bigskip
次に勾配の計算およびpred\_init更新部分のコードを示す。今回は最急降下法のイタレーション回数を10000回とした。初めの4行はpred\_init及びその近傍のLorenz63モデル結果を計算している。その後それぞれの差分から勾配を近似計算し、pred\_initの更新を行った。\bigskip
\begin{python}
for itr in range(10000):
	x = Lorenz63(pred_init[0], pred_init[1], pred_init[2], noise = False)
	x_diff = Lorenz63(pred_init[0]+dh, pred_init[1], pred_init[2], noise = False)
	y_diff = Lorenz63(pred_init[0], pred_init[1]+dh, pred_init[2], noise = False)
	z_diff = Lorenz63(pred_init[0], pred_init[1], pred_init[2]+dh, noise = False)

	gradxJ = (J(y, x_diff)-J(y, x))/dh
	gradyJ = (J(y, y_diff)-J(y, x))/dh
	gradzJ = (J(y, z_diff)-J(y, x))/dh

	pred_init[0] -= alpha*gradxJ
	pred_init[1] -= alpha*gradyJ
	pred_init[2] -= alpha*gradzJ
\end{python}\bigskip
学習がうまく行けばpred\_init=(1, 0, 0)となるはずだが上手くいかず、結果は(-0.3, 1.5, -1.8)となった。ただし、$\bm x_0=(1, 0, 0)$と(-0.3, 1.5, -1.8)のときの$x$の結果を比較したところ、カオス性が増す後半以外は一致している(図12)。なにより適当な最急降下法や差分計算を考えれば、初期値に敏感なLorenz63モデルとしてはそこそこ良いんじゃないかなと思える。\par
以上のコードを纏めたものを以下に記す。\bigskip
\begin{python}
import numpy as np

def J(x, y):
	return np.mean((y-x)**2)/8.

y = Lorenz63()

pred_init = np.array([0., 0., 0.])
dh = 0.001
alpha = 1e-3

for itr in range(10000):
	x = Lorenz63(pred_init[0], pred_init[1], pred_init[2], noise = False)
	x_diff = Lorenz63(pred_init[0]+dh, pred_init[1], pred_init[2], noise = False)
	y_diff = Lorenz63(pred_init[0], pred_init[1]+dh, pred_init[2], noise = False)
	z_diff = Lorenz63(pred_init[0], pred_init[1], pred_init[2]+dh, noise = False)

	gradxJ = (J(y, x_diff)-J(y, x))/dh
	gradyJ = (J(y, y_diff)-J(y, x))/dh
	gradzJ = (J(y, z_diff)-J(y, x))/dh

	pred_init[0] -= alpha*gradxJ
	pred_init[1] -= alpha*gradyJ
	pred_init[2] -= alpha*gradzJ
\end{python}

\subsection{MCMC法による事後分布推定}
本節では一風変わったデータ同化を紹介する。これは式(39)に従って$\bm x_0$をサンプリングする手法である。つまり、式(39)の分布を式(22)の形で表現する。ただし、$p(\bm x_0|Y)$の確率分布を求めてからそれに従ってサンプリングするような、二度手間なことはしない。それよりも効率よくサンプリングするために、マルコフ連鎖モンテカルロ法(MCMC法)を利用する。MCMC法はベイズ統計でよく用いられており、様々なサンプリング手法を一括りにした総称である(MCMC法だけで一冊の本が書ける)。本資料では最も簡単なMCMC法の一つ、メトロポリス法を紹介する。

\subsubsection{メトロポリス法}
確率分布$p(x)$からサンプリングする方法を考える。ここで$x$は連続確率変数であり、任意の$p(x)$を把握もしくは計算できるものとする(上記で$p(\bm x_0|Y)$を把握せずにサンプリングするよう述べたので矛盾に感じるかもしれないが、一旦忘れてほしい。最終的に解決させる)。\par
メトロポリス法は焼きなまし法に似ている。まず、適当な初期位置$x^0$から初め、$p(x^0)$を計算する。次に$x^0$からランダム変数$\epsilon$だけ移動し$x^1=x^0+\epsilon$の確率値$p(x^1)$を計算する。ただし、$p(x^0)>p(x^1)$ならば$1-p(x^1)/p(x^0)$の確率で$x$の更新を取り消し、$x^1=x^0$とする。\par
これを$x^2, x^3...$と繰り返したときのデータセット$\{ x^i|i=0, ..., N \}$について、図13を使って考えていこう。図13(a)に示す通り、$p(x^0)\leq p(x^1)$ならばデータ$x^t$は無条件に更新される。一方で確率値が減少する方向の場合、確率$1-p(x^1)/p(x^0)$でその場に留まる。したがってこのサンプリング方法は高確率な部分を優先的に選んでいる。一方で確率$p(x^1)/p(x^0)$で確率値の低いデータも許すため、極大値のみサンプリングしすぎるようにはなっていない。このようなサンプリング手法をメトロポリス法と言う。\par
しかしながら、この方法は初期位置$x^0$に依存する。図13(b)のように初期位置が分布の裾にある場合、高確率な位置に移動するまである程度タイムステップを要する。それまでのデータは確率値の低いところにあるため、確率分布に従ったサンプルとは言えない。妥当なサンプリングになるまでに要する時間のことをバーンイン期間と言う。したがって、メトロポリス法を用いたのち、バーンイン期間のデータを捨てたもの$\{ x_i|i=b, ...,N \}$をサンプリング結果として使う(ここで$b$はバーンイン期間後のタイムステップ値)。残念ながらバーンイン期間の良い見積もり方法を私は知らない。\par
最後に、メトロポリス法のアルゴリズムを記す。

\begin{tcolorbox}[title=メトロポリス法]
\begin{enumerate}
\item 初期値$x$を設定する。
\item $x$からランダム変数$\epsilon$だけ移動させる。$x' \leftarrow x+\epsilon$。
\item 2.に関して$p(x')<p(x)$の場合、確率$1-p(x')/p(x)$で$x'$の移動を取り消す。$x' \leftarrow x$。
\item $x \leftarrow x'$。
\item 2.-5.を繰り返す。各ステップの$x$を保存。
\item バーンイン期間の$x$を取り除く。
\end{enumerate}
\end{tcolorbox}

\begin{figure}[t]
\begin{center}
\includegraphics[width=12cm]{"fig13.png"}
\caption{(a)メトロポリス法のサンプリング方法。(b)バーンイン期間のイメージ。}
\end{center}
\end{figure}

\subsubsection{pythonコード実装例}
メトロポリス法を用いて標準正規分布$\mathcal{N}(0, 1)$からのサンプリングを試みる。まず、xの初期値を[-1,1]の一様乱数で生成する。バーンイン期間を100とし、10000のサンプルを生成することにした。サンプルデータはリストXに保存していく。\bigskip
\begin{python}
import numpy as np

burn_in = 1000
num = 10000
x = 2.*(np.random.rand()-0.5)

X = []; X.append(x)
\end{python}\bigskip
次にメトロポリス法に従いサンプリングしていく。xを[-0.1, 0.1]の一様乱数で更新しコード中のx\_nextを得る。xとx\_nextの確率値を比較し、Xに格納する方を決める。これをバーンイン期間と所望のサンプル数だけ繰り返す。最後にX=X[burn\_in+1:]とすることでバーンイン期間のデータを捨てる。\bigskip
\begin{python}
for itr in range(burn_in+num):
	x_next = x + 0.2*(np.random.rand()-0.5)

	p = np.exp(-x**2 / 2) / np.sqrt(2 * np.pi)
	p_next = np.exp(-x_next**2 / 2) / np.sqrt(2 * np.pi)

	if p_next < p:
		r = 1. - p_next/p
		if np.random.rand() < r:
			X.append(x)
		else:
			X.append(x_next)
	else:
		X.append(x_next)

	x = X[-1]

X = X[burn_in+1:]
\end{python}\bigskip
以下はこれまでのコードを纏めたものである。また、図14にサンプリング結果を示す。\bigskip
\begin{python}
import numpy as np

burn_in = 1000
num = 10000
x = 2.*(np.random.rand()-0.5)

X = []; X.append(x)

for itr in range(burn_in+num):
	x_next = x + 0.2*(np.random.rand()-0.5)

	p = np.exp(-x**2 / 2) / np.sqrt(2 * np.pi)
	p_next = np.exp(-x_next**2 / 2) / np.sqrt(2 * np.pi)

	if p_next < p:
		r = 1. - p_next/p
		if np.random.rand() < r:
			X.append(x)
		else:
			X.append(x_next)
	else:
		X.append(x_next)

	x = X[-1]

X = X[burn_in+1:]
\end{python}

\begin{figure}[b]
\begin{center}
\includegraphics[width=8cm]{"fig14.png"}
\caption{メトロポリス法によるサンプリング結果。}
\end{center}
\end{figure}

\subsubsection{事後分布に従うサンプリング方法}
ここからはデータ同化に戻り、式(39)に従うサンプリングを考える。ただし、繰り返しになるが確率分布$p(\bm x_0|Y)$を調べてからサンプリングするような、二度手間なことはしない。\par
一方で事前分布$p(\bm x_0)$に関しては、任意の$\bm x_0$に対して確率値を把握しているとする。そこでメトロポリス法の利用を検討する。\par
まず$\bm x_0$の初期値$\bm x^0$を設定する。$\bm x^0$のときの尤度$p(Y|\bm x^0)$はこれまで通り求めることができる。したがって$\bm x^0$のときの事後確率は
\begin{equation}
p(\bm x^0|Y)=Cp(\bm x^0)p(Y|\bm x^0) \notag
\end{equation}
となる(ここで$C$は規格化係数)。そして$\bm x^0$をランダムに移動させた$\bm x^1=\bm x^0+\bm \epsilon$に関しても同様に事後確率
\begin{equation}
p(\bm x^1|Y)=Cp(\bm x^1)p(Y|\bm x^1) \notag
\end{equation}
を計算することができる(なお、ベイズの定理より規格化係数は両式とも同じ値である)。確率値の比
\begin{equation}
\frac{p(\bm x^1|Y)}{p(\bm x^0|Y)}=\frac{p(\bm x^0)}{p(\bm x^1)}\frac{p(Y|\bm x^1)}{p(Y|\bm x^0)} \notag
\end{equation}
をもとに$\bm x$の位置を決める。

これを繰り返した結果$\{ \bm x^i | i=b, ..., N+b\}$は事後分布に関するサンプルデータとなる。従って事後分布は式(22)より
\begin{equation}
p(\bm x_0|Y) \simeq \frac{1}{N-b+1}\sum_{i=b}^N \delta(\bm x_0-\bm x^i) \notag
\end{equation}
と推定される。

\subsubsection{pythonコード例}
MCMC法を用いてLorenz63モデルの初期位置$\bm x_0$の事後分布を求める。下記コードの通り、学習データyは100タイムステップまでとした。またバーンイン期間を1000ステップ、サンプル数を10000とした。$\bm x_0$の事前分布は$\mathcal{N}(\bm \mu, I)$、$\bm \mu=(0.5, 0., 0.)^{\rm T}$とした。コード中にある通り、メトロポリス法の初期位置x0を事前分布に従って抽出した。また、リストXでサンプルデータを格納していく。\bigskip
\begin{python}
import numpy as np

time_step = 100
y = Lorenz63(time_step = time_step)

burn_in = 1000
num = 10000

x0 = np.random.normal(0., 1., size = 3) + np.array([0.5, 0., 0.])
X0 = []; X0.append(x0)
\end{python}\bigskip
メトロポリス法のため、バーンイン期間と所望のサンプル数だけの繰り返し計算を行っていく。下記コード中のx0\_nextはメトロポリス法における更新点である。また、Hx0(Hx0\_next)は初期位置がx0(x0\_next)のときのLorenz63モデルである。\bigskip
\begin{python}
for itr in range(burn_in+num):
	x0_next = x0 + 0.2*(np.random.rand(3)-0.5)

	Hx0 = Lorenz63(x0[0], x0[1], x0[2], noise = False, time_step = time_step)
	Hx0_next = Lorenz63(x0_next[0], 
		x0_next[1], x0_next[2], noise = False, time_step = time_step)
\end{python}\bigskip
次に事後分布の比率を計算する。まず尤度の比率は下記の関数ratioLikより求めた。なお、観測ノイズは$\mathcal{N}(\bm 0, 4I)$である。また、式(39)より$1/(2\pi)^{3/2}/|\Sigma|^{1/2}$は両者で共通するため、尤度の比率計算では${\rm exp}(\cdot)$のみ考慮すればよい。また、尤度が非常に小さい場合、丸め誤差が問題になってくる。そのため、下記関数のようにタイムステップ毎に尤度の比を計算することで、丸め誤差を防いだ。\bigskip
\begin{python}
def ratioLik(y, Hx, Hx_next):
	r = 1.
	for iy, iHx, iHx_next in zip(y, Hx, Hx_next):
		Lx = np.exp(-np.sum((iy-iHx)**2)/8.)
		Lx_next = np.exp(-np.sum((iy-iHx_next)**2)/8.)

		r *= Lx_next/Lx

	return r
\end{python}\bigskip
尤度の比を先ほどのforループの中で受け取る(コード中rL)。また、事前分布の比(rP)は正規分布の比より求まる。ただし、こちらも$1/(2\pi)^{3/2}$は共通すること、並びに事前分布中の$x$、$y$、$z$は独立であることから、このような書き方になっている。両者の積より事後分布の比rを求めた。\bigskip
\begin{python}
for itr in range(burn_in+num):
	rL = ratioLik(y, Hx0, Hx0_next)
	rP = np.exp(-((x0_next[0]-0.5)**2+x0_next[1]**2+x0_next[2]**2) / 2) / \
		np.exp(-((x0[0]-0.5)**2+x0[1]**2+x0[2]**2) / 2)
	r = rL*rP
\end{python}\bigskip
最後にメトロポリス法に従いサンプリングを行う。サンプリング過程及びこれまでのコードを纏めたものを以下に示す。\bigskip
\begin{python}
import numpy as np

def ratioLik(y, Hx, Hx_next):
	r = 1.
	for iy, iHx, iHx_next in zip(y, Hx, Hx_next):
		Lx = np.exp(-np.sum((iy-iHx)**2)/8.)
		Lx_next = np.exp(-np.sum((iy-iHx_next)**2)/8.)

		r *= Lx_next/Lx

	return r

time_step = 100
y = Lorenz63(time_step = time_step)

burn_in = 1000
num = 10000

x0 = np.random.normal(0., 1., size = 3) + np.array([0.5, 0., 0.])
X0 = []; X0.append(x0)

for itr in range(burn_in+num):
	x0_next = x0 + 0.2*(np.random.rand(3)-0.5)

	Hx0 = Lorenz63(x0[0], x0[1], x0[2], noise = False, time_step = time_step)
	Hx0_next = Lorenz63(x0_next[0], 
				x0_next[1], x0_next[2], noise = False, time_step = time_step)

	rL = ratioLik(y, Hx0, Hx0_next)
	rP = np.exp(-((x0_next[0]-0.5)**2+x0_next[1]**2+x0_next[2]**2) / 2) / \
		np.exp(-((x0[0]-0.5)**2+x0[1]**2+x0[2]**2) / 2)
	r = rL*rP

	if r < 1.:
		if np.random.rand() < (1.-r):
			X0.append(x0_next)
		else:
			X0.append(x0)
	else:
		X0.append(x0_next)

	x0 = X0[-1]
\end{python}\bigskip
本コードを実行したところ、$\bm x_0$の各要素の分布は図15のようになった(各要素毎にヒストグラムを作成しているので、これは$\bm x_0$の同時確率分布ではなく各要素の周辺確率を見ていることに注意)。正解がそれぞれ(1, 0, 0)であることを考えるとあまり良くないかもしれない。ただしLorenz63モデルは初期値にかなり敏感なので、非逐次型データ同化で解こうとすると、こんなものだと思われる。

\begin{figure}[t]
\begin{center}
\includegraphics[width=8cm]{"fig15.png"}
\caption{メトロポリス法でサンプリングされた$\bm x_0$の事後分布。}
\end{center}
\end{figure}

\section{逐次型データ同化}
\subsection{カルマンフィルタ(KF)}
本章から逐次型データ同化に進む。逐次型データ同化で基礎にあたるのはカルマンフィルタ(KF)であろう。\par
私たちは2.3.3節でベイズ機械学習の更新アルゴリズム的観点を学んだ。式(33)(34)のように計算がシンプルになった理由は、事前分布と尤度を正規分布で統一したこと、並びにパラメータに対して線形変換しか施さなかったことにある。KFもこの特性を存分に利用する。\par
まず4.2.2節の$p(\bm x_{t-1})$と尤度、並びにシステムノイズ$\bm v_t$も正規分布と仮定する。また、それだけではなくシステムモデルも線形変換であると仮定する。そのため、式(37)の代わりに行列$F$を用いて
\begin{equation}
\bm x_t=F\bm x_{t-1}+\bm v_t \notag
\end{equation}
なるシステムモデルを考える。$\bm x_{t-1}$は正規分布に従うので$\bm x_{t}$も正規分布に従う(正規分布の線形変換)。システムノイズの確率分布を$\mathcal{N}(\bm 0, V)$、$p(\bm x_{t-1})$を$\mathcal{N}(\bm \mu_{t-1}, S_{t-1})$としたとき、$p(\bm x_t)$は
\begin{equation}
p(\bm x_t)=\mathcal{N}(\bm \mu_t, S_t),~~~ \bm \mu_t=F\bm \mu_{t-1},~~~S_t=
FS_{t-1}F^{\rm T}+V
\end{equation}
となる。\par
KFはこれだけでなく、観測モデルに対しても線形であることを仮定する(4.1.2節の例1と2が線型な観測モデルに当てはまる)。つまり式(38)の代わりに、行列$H$を用いた
\begin{equation}
\bm y_t=H\bm x_t+\bm w_t \notag
\end{equation}
なる観測モデルを考える。導出は省略するが、このときの事後分布$p(\bm x_t|\bm y_t)$も正規分布になる。観測ノイズ$\bm w_t$が$\mathcal{N}(\bm 0, \Sigma)$に従うとしたとき、$p(\bm x_t|\bm y_t)$は
\begin{equation}
p(\bm x_t|\bm y_t)=\mathcal{N}(\bm \mu'_t, S'_t),~~~
\mu'_t=\mu_t+K_t(\bm y_t-H\bm \mu_t),~~~
S'_t=(I-K_tH)S_t
\end{equation}
となる。ここで$K_t$はカルマンゲインと言い、
\begin{equation}
K_t=S_tH^{\rm T}(HS_tH^{\rm T}+\Sigma)^{-1}
\end{equation}
である。\par
このようにKFは式(42)(43)の繰り返し計算をするだけで学習できるため、計算コストが少なく済む。しかしながら、CAEを用いたデータ同化ではあまり用いられない。線型なシステムモデルという仮定はときに大胆すぎる。非線形な流体現象の場合、線型なサロゲートモデルがない限りKFの利用は難しい。\par
ならば音響などの線型問題ならばどうかと言うと、これも難しいときがある。KFが線型な物理現象ではなく、ベクトル$\bm x_t$に対する線型性を仮定していることに注意してほしい。4.1.1で示した通り、この$\bm x$には物理場$\bm u$だけでなくパラメータ$\bm w$も含まれている。音響解析における$\bm w$として音速や壁面インピーダンスなどが挙げられるが、それらはシステムモデルの行列$F$の中にも含まれている。このような場合は$\bm x$から見た音響解析は非線型であり、KFの仮定を満たさない。\par
以上の理由から、CAEを用いたデータ同化でKFを利用することは稀である。

\subsection{アンサンブルカルマンフィルタ(EnKF)}
KFの考え方を踏襲しつつ、非線型なシステムモデルに対応可能な手法としてアンサンブルカルマンフィルタ(EnKF)がある。EnKFでも確率分布は正規分布しか現れない。非線型なシステムモデル$\bm x_t=F(\bm x_{t-1})+\bm v_t$を考える場合、たとえ$p(\bm x_{t-1})$が正規分布に従うとしても$p(\bm x_t)$は正規分布に従わない。しかしながら、EnKFは近似的に正規分布であることを維持しようとする。\par
まず初期時刻の$\bm x_0$に関して、事前分布$p(\bm x_0)$に従い$N$個サンプリングする。このときのアンサンブルを$\{ \bm x^i_0|i=1,...,N \}$で表す。次に各粒子に対してシステムモデルを施し、
\begin{equation}
\bm x^i_1=F(\bm x^i_0)+\bm v_t \notag
\end{equation}
を得る。このアンサンブルは$p(\bm x_t)$をよく表していると考えられるだろう。そこで、$p(\bm x_t)$を正規分布だと仮定し、その分散共分散行列$S_1$を
\begin{equation}
S_1=\frac{1}{N-1}\sum_i(\bm x^i_1-\bm \mu_1)(\bm x^i_1-\bm \mu_1)^{\rm T} \notag
\end{equation}
より推定する。ここで$\mu_1=\sum_i \bm x^i_1/N$である。なお上式が$N$ではなく$N-1$で割っている理由は、これが分散共分散行列の不偏推定量になるためである(詳しくは統計学の書籍を参照のこと)。最後に、式(43)に倣って、各粒子を
\begin{equation}
\bm x^i_1 \leftarrow \bm x^i_1 + K_1(\bm y_1-H\bm x^i_1) \notag
\end{equation}
で更新する。ここで$K_1$はカルマンゲインであり、式(44)に倣って
\begin{equation}
K_1=S_1H^{\rm T}(HS_1H^{\rm T}+\Sigma)^{-1} \notag
\end{equation}
と定義する。\par
最終的に得られたアンサンブル$\{ \bm x^i_1 |i=1,...,N \}$は正に事後分布、つまり$p(\bm x_1|\bm y_1)$をよく表している。これを繰り返すことでEnKFは学習していく。以下にEnKFのアルゴリズムを記す。
\begin{tcolorbox}[title=アンサンブルカルマンフィルタ]
\begin{enumerate}
\item 事前分布に従いアンサンブル$\{ \bm x^i | i=1,...,N \}$を生成する。
\item $\bm x^i \leftarrow F(\bm x^i)+\bm v_0$。
\item アンサンブルから分散共分散行列
\begin{equation}
S=\frac{1}{N-1}\sum_i(\bm x^i-\bm \mu)(\bm x^i-\bm \mu)^{\rm T}
\end{equation}
を計算する。ここで$\bm \mu=\sum_i\bm x^i/N$。
\item 各粒子を尤度計算に従い、
\begin{equation}
\bm x^i \leftarrow \bm x^i + K(\bm y-H\bm x^i)
\end{equation}
で更新する。ここで$K$は
\begin{equation}
K=SH^{\rm T}(HSH^{\rm T}+\Sigma)^{-1}
\end{equation}
であり、カルマンゲインと言う。
\item 2.-4.を繰り返す。
\end{enumerate}
\end{tcolorbox}
非線型なシステムモデルを扱えるようになったが、KFのときと変わらず計算が容易なところも見られる。ただし、各粒子の更新時に粒子の数$N$だけのシステムモデル、つまりCAE解析が必要になる。当然ながら$N$の数が少ないとアンサンブルによる確率分布の信憑性が低くなる。計算コストと精度を鑑みて粒子数を決めなければならない。

\subsubsection{pythonコード例}
EnKFによるLorenz63モデルのデータ同化を試みる。観測ノイズはこれまで通り$\mathcal{N}(\bm 0, 4I)$とした。従って$\Sigma=4I$である。また、観測値$\bm y$と状態ベクトル$\bm x$は同じものなので、$H=I$となる。以上よりカルマンゲインは$K=S(S+4I)^{-1}$となる。\par
今回は400タイムステップまでの解析を行う。これまで同様学習データyを前もって生成しておいた。また、EnKFの粒子数Nは100とした。xはN行3列の配列であり、アンサンブルを表す。今回は事前分布を$\mathcal{N}((-2, 0, 0)^{\rm T}, I)$とし、それに従うようサンプリングした。\bigskip
\begin{python}
import numpy as np

time_step = 400
y = Lorenz63(time_step = time_step)
R = 4.*np.eye(3)

N = 100
x = np.random.normal(0., 1., size = (N, 3)) + np.array([-2., 0., 0.])
\end{python}\bigskip
アンサンブルxから次時刻の状態に更新するシステムモデルをstepという関数で定義した。下記の通り、粒子毎にLorenz63の解析をしている。ただし逐次的データ同化なので一度に400タイムステップの解析をしていない点に注意してほしい。解析を途中で止め、そのときの事後分布を計算できるようにしている。なお、今回はシステムノイズを標準正規分布としている。\bigskip
\begin{python}
def step(x):
	x_next = []
	for ix in x:
		x_n = Lorenz63(ix[0], ix[1], ix[2], noise = False, time_step = 1)[0]
		x_next.append(x_n)

	x_next = np.stack(x_next, axis = 0)
	noise = np.random.normal(0., 1., size = x_next.shape)
	x_next += noise

	return x_next
\end{python}\bigskip
下記の通り、400タイムステップまでの繰り返し計算により解析を逐次的に行っている。x\_nextは関数stepの出力であり、次時刻のアンサンブルである。今回は10タイムステップ毎にデータ同化を行うことにした。\pythoninline{if (t+1)\%10 == 0:}とあるように、10タイムステップの周期でEnKFの処理を行っている。\bigskip
\begin{python}
for t in range(time_step):
	x_next = step(x)

	if (t+1)%10 == 0:
		mu = np.mean(x_next, axis = 0)
		Sigma = np.cov(x_next-mu, rowvar = False)

		K = Sigma@np.linalg.inv(Sigma+R)
		x_next += (y[t]-x_next)@K

	x = x_next
\end{python}\bigskip
これまでのコードを纏めたものを以下に示す。\bigskip
\begin{python}
import numpy as np

time_step = 400
y = Lorenz63(time_step = time_step)
R = 4.*np.eye(3)

N = 100
x = np.random.normal(0., 1., size = (N, 3)) + np.array([-2., 0., 0.])

def step(x):
	x_next = []
	for ix in x:
		x_n = Lorenz63(ix[0], ix[1], ix[2], noise = False, time_step = 1)[0]
		x_next.append(x_n)

	x_next = np.stack(x_next, axis = 0)
	noise = np.random.normal(0., 1., size = x_next.shape)
	x_next += noise

	return x_next

for t in range(time_step):
	x_next = step(x)

	if (t+1)%10 == 0:
		mu = np.mean(x_next, axis = 0)
		Sigma = np.cov(x_next-mu, rowvar = False)

		K = Sigma@np.linalg.inv(Sigma+R)
		x_next += (y[t]-x_next)@K

	x = x_next
\end{python}\bigskip \par
Lorenz63モデルの数値$x$について、観測値yとアンサンブルの平均値を比較した(図16)。観測データに対して学習結果の平均値はよく一致している。この結果は喜ばしいことだが、平均値が不自然ながたつきを見せていることに注意してほしい。4.2節で議論した通り、逐次型データ同化は現時刻(もしくは最終時刻)の尤もらしさにしか興味がない。尤度を高めるためなら途中時刻であっても状態ベクトルの不自然な(支配方程式に従わない)変化も認めている。そのため学習後に過去を含めた時系列を確かめたとき、このようながたつきが見られる。このようなことは非逐次型データ同化の結果(図12)では見られなかった。これは全時刻を俯瞰する非逐次型データ同化の長所と言える。
個人的には、オンライン学習の場合は逐次型データ同化の方が良いが、物性値推定のような逆解析的にデータ同化を用いたい場合は非逐次型データ同化を選ぶべきな気がしている。

\begin{figure}[t]
\begin{center}
\includegraphics[width=12cm]{"fig16.png"}
\caption{EnKFの結果。Lorenz63モデルの数値$x$に対し、(answer)観測データ、(average)アンサンブルの平均値、(+-std)平均値$\pm 3\sigma$。$\sigma$はアンサンブルにおける$x$の標準偏差。}
\end{center}
\end{figure}

\subsection{粒子フィルタ(PF)}
EnKFにすることで非線形なシステムモデルも扱えるようになった。しかしながら、相変わらず正規分布しか扱えないことと、線型な観測モデルという仮定が残っている。本節で紹介する粒子フィルタ(PF)はこれらの制約を受けない、非常に自由度の高い手法と言える。\par
粒子という言葉から想像できるように、PFは式(22)のアンサンブル表現によるノンパラメトリックベイズ機械学習である。以下はPFのアルゴリズムである。
\begin{tcolorbox}[title=粒子フィルタ]
\begin{enumerate}
\item 所望の事前分布$p(\bm x)$に従って粒子をサンプリングする。$\{ \bm x_i|i=1,...,N \}$。
\item $\bm x_i \leftarrow F(\bm x_i)+\bm v$。
\item 各粒子に対して尤度
\begin{equation}
\beta_i=p(\bm y|\bm x_i)=\frac{1}{(2\pi)^{m/2}|\Sigma|^{1/2}}{\rm exp}\left(
-\frac{1}{2}(\bm y-H(\bm x_i))^{\rm T}\Sigma^{-1}(\bm y-H(\bm x_i))
\right) \notag
\end{equation}
を計算する。
\item 各粒子の事前確率は$1/N$であるため、事後分布は$C\beta_i/N$となる。ここで$C$は規格化係数だが、確率の総和が1であることから$C=N/\sum_i \beta_i$であることが分かる。従って、各粒子の事後確率は$\beta_i/\sum_j \beta_j$と求まる。
\item 各粒子を$\beta_i/\sum_j \beta_j$の確率で再サンプリングし、事後分布に従うアンサンブルを得る。
\item 2.-5.を繰り返す。
\end{enumerate}
\end{tcolorbox}
上記の通り、PFは3.2節のベイズ機械学習と類似している。3.2節で見られた多様性維持のためのノイズは、システムノイズが担っている。そのため、PFではシステムノイズが重要になってくる。\par
EnKFもアンサンブルを利用するが、確率分布はいつも正規分布であったことを思い出してほしい。一方のPFはノンパラメトリック確率分布であるため、KFのときからあった制約が全てなくなっている。ただし、ノンパラメトリックである分、EnKFのときより多くのサンプル数が必要になる(少ないサンプル数だと確率分布が十分に表現できないことになる)。サンプル数の数だけシステムモデルの処理、つまりCAE解析が必要になってくるため、PFの計算コストは高い。一回当たりの解析時間が短く、低次元な状態モデルの問題にPFは向いている。

\subsubsection{pythonコード例}
PFを用いてLorenz63モデルのデータ同化を行う。基本的にEnKFのときと条件は同じだが、粒子数だけ500に変えた。\par
それ以外のEnKFのコードとの差分は下記の事後分布計算の所のみである。コード中betaは上記アルゴリズムの$\beta_i$の配列に相当する。ただし、これまでと同様に$1/(2\pi)^{3/2}/|\Sigma|^{1/2}$の部分は計算していない。probは各粒子の事後確率である。\pythoninline{np.random.choice(N, N, p=prob)}でサンプリングする粒子インデックスを決定し、次の行で実際にサンプリングしている。\bigskip
\begin{python}
for t in range(time_step):
	if (t+1)%10 == 0:
		beta = np.exp(-np.sum((y[t]-x_next)**2, axis = 1)/8.)
		prob = beta/np.sum(beta)

		index = np.random.choice(N, N, p=prob)
		x_next = x_next[index]
\end{python}\bigskip
EnKFと共通している部分も含めたコードを以下に記す。また、Lorenz63モデルの数値$x$について、観測値yとアンサンブルの平均値を比較した(図17)。\bigskip
\begin{python}
import numpy as np

def step(x):
	x_next = []
	for ix in x:
		x_n = Lorenz63(ix[0], ix[1], ix[2], noise = False, time_step = 1)[0]
		x_next.append(x_n)

	x_next = np.stack(x_next, axis = 0)
	noise = np.random.normal(0., 1., size = x_next.shape)
	x_next += noise

	return x_next

time_step = 400
y = Lorenz63(time_step = time_step)
R = 4.*np.eye(3)

N = 500
x = np.random.normal(0., 1., size = (N, 3)) + np.array([-2., 0., 0.])

for t in range(time_step):
	x_next = step(x)

	if (t+1)%10 == 0:
		beta = np.exp(-np.sum((y[t]-x_next)**2, axis = 1)/8.)
		prob = beta/np.sum(beta)

		index = np.random.choice(N, N, p=prob)
		x_next = x_next[index]

	x = x_next
\end{python}\bigskip

\begin{figure}[t]
\begin{center}
\includegraphics[width=12cm]{"fig17.png"}
\caption{PFの学習結果。Lorenz63モデルの数値$x$に対し(answer)観測データ、(average)アンサンブルの平均値、(+-std)平均値$\pm 3\sigma$。$\sigma$はアンサンブルにおける$x$の標準偏差。}
\end{center}
\end{figure}

\subsection{融合粒子フィルタ(MPF)}
PFは自由度が高い一方で、多様性の消滅(つまり退化)が問題になることが多い。退化の対策方法は今でも熱心に研究されており、様々なPFの派生形が提案されている。本資料ではそのうちの一つである融合粒子フィルタ(MPF)を紹介する。\par
お気付きになられた方もいるかと思うが、PFのアルゴリズムは進化計算と非常に似ている。前節のアルゴリズムの5.は、進化計算では世代交代と呼ばれている。また、システムノイズは突然変異に相当する。進化計算では突然変異の他に交叉がよく施されるが、MPFはPFに交叉の機能を加えたものと言える。\par
原著では、粒子のアンサンブル$\{ \bm x_i|i=1,...,N \}$から事後確率$\beta_i/\sum_i \beta_i$に従い3つの粒子$\{ \bm x^1, \bm x^2, \bm x^3 \}$をサンプリングする。そしてこれらの重み付き和
\begin{equation}
\bm x'_1=a_1\bm x^1+a_2\bm x^2+a_3\bm x^3 \notag
\end{equation}
を新しい粒子として考える。この$\bm x$は$\{ \bm x^1, \bm x^2, \bm x^3 \}$と異なる値なので、多様性の増加(もしくは維持)ができそうである。この処理を$N$回繰り返し、新しくできた粒子のアンサンブル$\{ \bm x'_i|i=1,...,N \}$を事後分布として扱う。以下はMPFのアルゴリズムである。
\begin{tcolorbox}[title=融合粒子フィルタ]
\begin{enumerate}
\item 所望の事前分布$p(\bm x)$に従って粒子をサンプリングする。$\{ \bm x_i|i=1,...,N \}$。
\item $\bm x_i \leftarrow F(\bm x_i)+\bm v$。
\item 各粒子に対して尤度
\begin{equation}
\beta_i=p(\bm y|\bm x_i)=\frac{1}{(2\pi)^{m/2}|\Sigma|^{1/2}}{\rm exp}\left(
-\frac{1}{2}(\bm y-H(\bm x_i))^{\rm T}\Sigma^{-1}(\bm y-H(\bm x_i))
\right) \notag
\end{equation}
を計算する。
\item 各粒子の事前確率は$1/N$であるため、事後分布は$C\beta_i/N$となる。ここで$C$は規格化係数だが、確率の総和が1であることから$C=N/\sum_i \beta_i$であることが分かる。従って、各粒子の事後確率は$\beta_i/\sum_j \beta_j$と求まる。
\item 各粒子を$\beta_i/\sum_j \beta_j$の確率で$N$個だけ再サンプリングする。
\item 5.のアンサンブルから粒子を3個サンプリングする。サンプリングされた粒子$\{ \bm x^1, \bm x^2, \bm x^3 \}$から、新しい粒子
\begin{equation}
\bm x=a_1\bm x^1+a_2\bm x^2+a_3\bm x^3
\end{equation}
を生成する。これを$N$回繰り返し、新しいアンサンブルを得る。
\item 2.-6.を繰り返す。
\end{enumerate}
\end{tcolorbox}
式(48)の係数$a_i$は何でもよい訳ではない。たとえば$a_1=a_2=a_3=0$の場合、新しい粒子は常に$\bm 0$になってしまう。これは大げさな例だが、原著では2つの制約を提言している。\par
アルゴリズム中5.で得られたアンサンブルは事後分布に従っている。事後分布はベイズ機械学習に則って求められたので、それを式(48)で崩してしまうのはよくない。例えば正規分布は和や線型変換で平均や分散が変わってしまう。このようなことが式(48)でも起こっていると考えられる。\par
しかしながら、原著によると、確率分布の期待値、分散、尖度などあらゆる代表値を維持するように、係数$a_i$を設定することは不可能らしい。そこで、少なくとも期待値と分散は式(48)から得られたアンサンブルでも維持されるよう、
\begin{equation}
a_1+a_2+a_3=1,~~~a_1^2+a_2^2+a_3^2=1
\end{equation}
なる制約式を提言している。

\subsubsection{pythonコード例}
MPFでLorenz63モデルのデータ同化を行う。係数は
\begin{equation}
a_1=\frac{2}{3},~~~a_2=\frac{2}{3},~~~a_3=-\frac{1}{3} \notag
\end{equation}
とした。MPFとPFの差分はサンプリング部分のみである。PFと同様に事後確率probを求め、N個のサンプリングを3種用意する。それぞれのサンプリング結果を$a_i$の重み付き和で計算すれば、アルゴリズムの6.が実行されたことになる。\bigskip
\begin{python}
for t in range(time_step):
	if (t+1)%10 == 0:
		index_1 = np.random.choice(N, N, p=prob)
		index_2 = np.random.choice(N, N, p=prob)
		index_3 = np.random.choice(N, N, p=prob)

		x_next = (2./3.)*x_next[index_1] \
			 + (2./3.)*x_next[index_2] \
			 - (1./3.)*x_next[index_3]
\end{python}\bigskip
以下はMPFの全コードである(今回の問題だと、PFとほとんど結果は変わらなかった)。\bigskip
\begin{python}
import numpy as np


def step(x):
	x_next = []
	for ix in x:
		x_n = Lorenz63(ix[0], ix[1], ix[2], noise = False, time_step = 1)[0]
		x_next.append(x_n)

	x_next = np.stack(x_next, axis = 0)
	noise = np.random.normal(0., 1., size = x_next.shape)
	x_next += noise

	return x_next

time_step = 400
y = Lorenz63(time_step = time_step)
R = 4.*np.eye(3)

N = 500
x = np.random.normal(0., 1., size = (N, 3)) + np.array([-2., 0., 0.])

for t in range(time_step):
	x_next = step(x)

	if (t+1)%10 == 0:
		beta = np.exp(-np.sum((y[t]-x_next)**2, axis = 1)/8.)
		prob = beta/np.sum(beta)

		index_1 = np.random.choice(N, N, p=prob)
		index_2 = np.random.choice(N, N, p=prob)
		index_3 = np.random.choice(N, N, p=prob)
		
		x_next = (2./3.)*x_next[index_1] \
			 + (2./3.)*x_next[index_2] \
			 - (1./3.)*x_next[index_3]

	x = x_next
\end{python}

\section*{さいごに(参考図書紹介)}
~\\
{\bf 「統計学入門」東京大学教養学教室(編)}\par
ベイズ統計ではない、いわゆる一般的な統計学に関する本。序文から内容が素晴らしく、考え方が参考になる。\\
{\bf 「パターン認識と機械学習」C.M.ビショップ(著)}\par
頻度主義とベイズを上手く比較した名著。3章まで読むとよい。\\
{\bf 「データ同化流体科学」大林茂ら(著)}\par
データ同化を広く扱った書籍。タイトルに流体とあるが、他分野の人にとっても役に立つ。\\
{\bf 「データ同化-観測・実験とモデルを融合するイノベーション-」淡路敏之ら(著)}\par
冒頭から説明がかなり不親切。購入したことを後悔。\\
{\bf 「データ同化入門」樋口知之ら(著)}\par
逐次型データ同化に特化した書籍。内容も濃く参考になった。本資料では取り扱っていない平滑化も説明している。





\end{document}














